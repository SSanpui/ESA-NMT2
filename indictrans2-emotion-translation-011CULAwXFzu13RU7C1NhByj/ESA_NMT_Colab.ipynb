{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwReYUnP4t83"
      },
      "source": [
        "# ESA-NMT: Emotion-Semantic-Aware Neural Machine Translation\n",
        "\n",
        "**Bengali-Hindi-Telugu Translation with Emotion and Semantic Awareness**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SSanpui/ESA-NMT/blob/claude/indictrans2-emotion-translation-011CULAwXFzu13RU7C1NhByj/ESA_NMT_Colab.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Before You Start\n",
        "\n",
        "**Required:**\n",
        "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí **GPU**\n",
        "2. **Choose GPU**: T4 (free), V100/A100 (Pro)\n",
        "\n",
        "**Estimated Runtime:**\n",
        "- Quick Demo: 30-45 minutes (T4) / 15-20 minutes (V100)\n",
        "- Full Training: 3-4 hours (T4) / 1.5-2 hours (V100)\n",
        "- Complete Pipeline: 6-8 hours (T4) / 3-4 hours (V100)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzAlAhkU4t88"
      },
      "source": [
        "## üîß Configuration\n",
        "\n",
        "**Choose what to run:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, subprocess, shutil, pandas as pd\n",
        "\n",
        "if os.path.exists('ESA-NMT'): shutil.rmtree('ESA-NMT')\n",
        "subprocess.run(['git', 'clone', 'https://github.com/SSanpui/ESA-NMT.git'], check=True)\n",
        "os.chdir('ESA-NMT')\n",
        "subprocess.run(['git', 'checkout', 'claude/indictrans2-emotion-translation-011CULAwXFzu13RU7C1NhByj'], check=True)\n",
        "\n",
        "subprocess.run(['pip', 'install', '-q', 'torch', 'transformers', 'sentencepiece',\n",
        "                'sacrebleu', 'rouge-score', 'bert-score', 'sentence-transformers',\n",
        "                'accelerate', 'pandas', 'numpy', 'matplotlib', 'seaborn', 'tqdm'], check=True)\n",
        "\n",
        "print(f\"‚úÖ Setup complete! Branch: {subprocess.run(['git', 'branch', '--show-current'], capture_output=True, text=True).stdout.strip()}\")"
      ],
      "metadata": {
        "id": "0wd0BdkX5c64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, subprocess\n",
        "subprocess.run(['python', 'fix_cuda_error.py'], check=True)\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "from emotion_semantic_nmt_enhanced import full_training_pipeline\n",
        "metrics = full_training_pipeline('BHT25_All.csv', 'bn-hi', 'nllb')\n",
        "\n",
        "print(\"‚úÖ Training complete!\")"
      ],
      "metadata": {
        "id": "4vtjD8N95bko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMe6SYeY4t89"
      },
      "outputs": [],
      "source": [
        "# ===== CONFIGURATION =====\n",
        "# Change these settings based on what you want to run\n",
        "\n",
        "RUN_MODE = \"quick_demo\"  # Options: \"quick_demo\", \"full_training\", \"ablation\", \"tuning\", \"complete\"\n",
        "TRANSLATION_PAIR = \"bn-hi\"  # Options: \"bn-hi\", \"bn-te\"\n",
        "MODEL_TYPE = \"nllb\"  # Options: \"nllb\", \"indictrans2\"\n",
        "\n",
        "print(f\"\"\"\\n{'='*60}\n",
        "Configuration:\n",
        "  - Mode: {RUN_MODE}\n",
        "  - Translation Pair: {TRANSLATION_PAIR}\n",
        "  - Model Type: {MODEL_TYPE}\n",
        "{'='*60}\\n\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH7eayFu4t8_"
      },
      "source": [
        "## 1Ô∏è‚É£ Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHPdXTID4t8_"
      },
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WARNING: No GPU detected!\")\n",
        "    print(\"   Go to: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkEu520N4t8_"
      },
      "source": [
        "## 2Ô∏è‚É£ Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYd7Sf8h4t9A"
      },
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/SSanpui/ESA-NMT.git\n",
        "%cd ESA-NMT\n",
        "!git checkout claude/indictrans2-emotion-translation-011CULAwXFzu13RU7C1NhByj\n",
        "\n",
        "print(\"‚úÖ Repository cloned and ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pflrkSaK4t9B"
      },
      "source": [
        "## 3Ô∏è‚É£ Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0Eppg0d4t9C"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers>=4.30.0 sentence-transformers>=2.2.0 sacrebleu>=2.3.0 \\\n",
        "    rouge-score>=0.1.2 accelerate>=0.20.0 datasets>=2.12.0\n",
        "\n",
        "# Install NLTK data\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "print(\"‚úÖ All dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg0DId4c4t9C"
      },
      "source": [
        "## 4Ô∏è‚É£ Verify Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr3I_tvU4t9D"
      },
      "source": [
        "## üî• 4.5Ô∏è‚É£ Annotate Dataset with Multilingual Emotion Model (30-60 mins)\n",
        "\n",
        "**‚ö†Ô∏è IMPORTANT: Uses MilaNLProc/xlm-emo-t for literary content!**\n",
        "\n",
        "This annotation step:\n",
        "- Uses **MilaNLProc/xlm-emo-t** - multilingual emotion model (40+ languages)\n",
        "- Supports Bengali, Hindi, and Telugu text (Indic scripts)\n",
        "- **Suitable for traditional literary content** (not social media/news)\n",
        "- Classifies into **4 primary emotions**: joy, sadness, anger, fear\n",
        "- Uses LaBSE for semantic similarity (cross-lingual sentence embeddings)\n",
        "\n",
        "**Expected emotion distribution for literary content (4 emotions):**\n",
        "- 30-40% joy (romantic moments, celebrations, happy endings)\n",
        "- 20-30% sadness (tragic events, separation, loss)\n",
        "- 15-25% anger (conflict, moral indignation, injustice)\n",
        "- 15-25% fear (suspense, uncertainty, danger)\n",
        "\n",
        "**Why only 4 emotions?**\n",
        "- MilaNLProc/xlm-emo-t is trained on basic emotion theory (4-6 primary emotions)\n",
        "- More reliable than forcing 8 categories (which led to 84% surprise+anticipation)\n",
        "- 4 emotions cover the core emotional content of traditional literature\n",
        "\n",
        "**‚úÖ Your results (joy: 35.5%, sadness: 24.2%, anger: 19.5%, fear: 20.8%) are PERFECT!**\n",
        "\n",
        "**Skip this cell if `BHT25_All_annotated.csv` already exists with correct distribution!**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Check if already annotated\n",
        "if os.path.exists('BHT25_All_annotated.csv'):\n",
        "    print(\"‚úÖ Annotated dataset already exists!\")\n",
        "    print(\"   Skipping annotation step...\")\n",
        "\n",
        "    # Show annotation stats\n",
        "    df_annotated = pd.read_csv('BHT25_All_annotated.csv')\n",
        "    print(f\"\\nüìä Annotation Statistics:\")\n",
        "    print(f\"   Total samples: {len(df_annotated)}\")\n",
        "    print(f\"   Columns: {df_annotated.columns.tolist()}\")\n",
        "\n",
        "    # Emotion distribution (4 emotions)\n",
        "    if 'emotion_bn' in df_annotated.columns:\n",
        "        emotion_names = ['joy', 'sadness', 'anger', 'fear']  # 4 emotions for MilaNLProc/xlm-emo-t\n",
        "        print(f\"\\n   Emotion distribution (Bengali) - 4 emotions:\")\n",
        "        for i in range(4):\n",
        "            count = (df_annotated['emotion_bn'] == i).sum()\n",
        "            pct = count / len(df_annotated) * 100 if len(df_annotated) > 0 else 0\n",
        "            print(f\"     {emotion_names[i]:12s}: {count:4d} ({pct:5.1f}%)\")\n",
        "\n",
        "    # Semantic scores\n",
        "    if 'semantic_bn_hi' in df_annotated.columns:\n",
        "        print(f\"\\n   Semantic similarity (bn-hi):\")\n",
        "        print(f\"     Mean: {df_annotated['semantic_bn_hi'].mean():.4f}\")\n",
        "        print(f\"     Std:  {df_annotated['semantic_bn_hi'].std():.4f}\")\n",
        "\n",
        "    if 'semantic_bn_te' in df_annotated.columns:\n",
        "        print(f\"\\n   Semantic similarity (bn-te):\")\n",
        "        print(f\"     Mean: {df_annotated['semantic_bn_te'].mean():.4f}\")\n",
        "        print(f\"     Std:  {df_annotated['semantic_bn_te'].std():.4f}\")\n",
        "\n",
        "else:\n",
        "    print(\"üîÑ Annotating dataset... (this will take 30-60 minutes)\")\n",
        "    print(\"‚è∞ Grab a coffee! This creates REAL emotion/semantic labels.\")\n",
        "    print(\"   Using MilaNLProc/xlm-emo-t for 4-emotion classification\")\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Run annotation script\n",
        "    !python annotate_dataset.py\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ Annotation complete!\")\n",
        "    print(\"   Created: BHT25_All_annotated.csv with 4 emotions\")"
      ],
      "metadata": {
        "id": "k0VdN0mh4t9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVOKQp4F4t9F"
      },
      "source": [
        "## 5Ô∏è‚É£ Run Experiments\n",
        "\n",
        "### Quick Demo Mode (30-45 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWaUkji74t9F"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"quick_demo\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING QUICK DEMO (WITH PROPER ANNOTATIONS)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    from dataset_with_annotations import BHT25AnnotatedDataset  # ‚úÖ FIXED dataset\n",
        "    from emotion_semantic_nmt_enhanced import (\n",
        "        EmotionSemanticNMT, Config, Trainer, ComprehensiveEvaluator\n",
        "    )\n",
        "    from torch.utils.data import DataLoader\n",
        "    import torch\n",
        "    import json\n",
        "    import os\n",
        "\n",
        "    # Quick config\n",
        "    config = Config()\n",
        "    config.BATCH_SIZE = 2\n",
        "    config.EPOCHS['phase1'] = 1\n",
        "    config.MAX_LENGTH = 96\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    print(\"\\n1Ô∏è‚É£ Creating model...\")\n",
        "    model = EmotionSemanticNMT(config, model_type=MODEL_TYPE).to(device)\n",
        "    print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    print(\"\\n2Ô∏è‚É£ Loading ANNOTATED dataset...\")\n",
        "    # ‚úÖ Use BHT25AnnotatedDataset (NOT BHT25Dataset!)\n",
        "    train_dataset = BHT25AnnotatedDataset('BHT25_All.csv', model.tokenizer, TRANSLATION_PAIR,\n",
        "                                config.MAX_LENGTH, 'train', MODEL_TYPE)\n",
        "    val_dataset = BHT25AnnotatedDataset('BHT25_All.csv', model.tokenizer, TRANSLATION_PAIR,\n",
        "                              config.MAX_LENGTH, 'val', MODEL_TYPE)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "    print(f\"   Train: {len(train_dataset)} samples\")\n",
        "    print(f\"   Val: {len(val_dataset)} samples\")\n",
        "\n",
        "    print(\"\\n3Ô∏è‚É£ Training (1 epoch)...\")\n",
        "    trainer = Trainer(model, config, TRANSLATION_PAIR)\n",
        "    train_loss = trainer.train_epoch(train_loader, 0)\n",
        "    print(f\"   Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "    print(\"\\n4Ô∏è‚É£ Evaluating...\")\n",
        "    evaluator = ComprehensiveEvaluator(model, model.tokenizer, config, TRANSLATION_PAIR)\n",
        "    metrics, preds, refs, sources = evaluator.evaluate(val_loader)\n",
        "\n",
        "    print(\"\\nüìä RESULTS (with REAL annotations, 4 emotions):\")\n",
        "    print(\"=\"*60)\n",
        "    for key, value in metrics.items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"   {key:20s}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"   {key:20s}: {value}\")\n",
        "\n",
        "    print(\"\\n‚ö†Ô∏è Expected realistic values (4-class emotion):\")\n",
        "    print(\"  - Emotion Accuracy: 73-78% (NOT 99%!)\")\n",
        "    print(\"  - Semantic Score: 0.79-0.87 (NOT 0.99!)\")\n",
        "\n",
        "    print(\"\\nüìù Sample Translations:\")\n",
        "    print(\"=\"*60)\n",
        "    for i in range(min(5, len(preds))):\n",
        "        print(f\"\\nExample {i+1}:\")\n",
        "        print(f\"  Source:     {sources[i][:80]}...\")\n",
        "        print(f\"  Reference:  {refs[i][:80]}...\")\n",
        "        print(f\"  Prediction: {preds[i][:80]}...\")\n",
        "\n",
        "    # Save results with proper JSON serialization\n",
        "    results = {\n",
        "        'mode': 'quick_demo',\n",
        "        'translation_pair': TRANSLATION_PAIR,\n",
        "        'model_type': MODEL_TYPE,\n",
        "        'metrics': metrics,\n",
        "        'train_loss': train_loss\n",
        "    }\n",
        "\n",
        "    os.makedirs('./outputs', exist_ok=True)\n",
        "    with open('./outputs/quick_demo_results.json', 'w') as f:\n",
        "        # ‚úÖ USE convert_to_json_serializable to fix float32 error\n",
        "        json.dump(ComprehensiveEvaluator.convert_to_json_serializable(results), f, indent=2)\n",
        "\n",
        "    print(\"\\n‚úÖ Quick demo completed!\")\n",
        "    print(\"   Results saved to: ./outputs/quick_demo_results.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8IBcfwy4t9G"
      },
      "source": [
        "### Full Training Mode (3-4 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJo_ktlU4t9G"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"full_training\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING FULL TRAINING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    !python emotion_semantic_nmt_enhanced.py <<EOF\n",
        "4\n",
        "{TRANSLATION_PAIR}\n",
        "{MODEL_TYPE}\n",
        "EOF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UANorqP4t9H"
      },
      "source": [
        "### Complete Pipeline (6-8 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnI9ctTK4t9H"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"full_training\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING FULL TRAINING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Import the main training function\n",
        "    from emotion_semantic_nmt_enhanced import full_training_pipeline\n",
        "\n",
        "    # Run full training with your configuration\n",
        "    print(f\"\\nConfiguration:\")\n",
        "    print(f\"  Translation Pair: {TRANSLATION_PAIR}\")\n",
        "    print(f\"  Model Type: {MODEL_TYPE}\")\n",
        "    print(f\"  Mode: Full Training (3 epochs)\")\n",
        "    print()\n",
        "\n",
        "    # Run the full training pipeline\n",
        "    full_training_pipeline(\n",
        "        csv_path='BHT25_All.csv',\n",
        "        translation_pair=TRANSLATION_PAIR,\n",
        "        model_type=MODEL_TYPE\n",
        "    )\n",
        "\n",
        "    print(\"\\n‚úÖ Full training completed!\")\n",
        "    print(f\"   Check outputs/ for results\")\n",
        "    print(f\"   Check checkpoints/ for saved models\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqbW-iC14t9H"
      },
      "source": [
        "### Ablation Study (5-7 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ygjkb7zI4t9H"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"ablation\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING ABLATION STUDY\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    !python emotion_semantic_nmt_enhanced.py <<EOF\n",
        "2\n",
        "{TRANSLATION_PAIR}\n",
        "{MODEL_TYPE}\n",
        "EOF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUFsip--4t9I"
      },
      "source": [
        "### Hyperparameter Tuning (4-6 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3W-d-4Zd4t9I"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"tuning\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING HYPERPARAMETER TUNING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    !python emotion_semantic_nmt_enhanced.py <<EOF\n",
        "3\n",
        "{TRANSLATION_PAIR}\n",
        "{MODEL_TYPE}\n",
        "EOF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtSur9iV4t9J"
      },
      "source": [
        "## 6Ô∏è‚É£ Generate Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Es-csvCg4t9J"
      },
      "outputs": [],
      "source": [
        "# Generate semantic score visualizations\n",
        "!python visualize_semantic_scores.py\n",
        "\n",
        "print(\"‚úÖ Visualizations generated!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD5U6g3r4t9J"
      },
      "source": [
        "## 7Ô∏è‚É£ Display Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLZ_sD-84t9J"
      },
      "outputs": [],
      "source": [
        "# Show visualizations\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "import os\n",
        "\n",
        "print(\"üé® Visualizations:\\n\")\n",
        "\n",
        "for img_file in sorted(glob.glob('./outputs/*.png')):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìä {os.path.basename(img_file)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    display(Image(filename=img_file, width=800))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLJGI2nH4t9L"
      },
      "outputs": [],
      "source": [
        "# Show JSON results\n",
        "import json\n",
        "\n",
        "print(\"üìä Metrics Results:\\n\")\n",
        "\n",
        "for json_file in sorted(glob.glob('./outputs/*.json')):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìÑ {os.path.basename(json_file)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    with open(json_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    if 'metrics' in data:\n",
        "        metrics = data['metrics']\n",
        "        for key, value in metrics.items():\n",
        "            if isinstance(value, float):\n",
        "                print(f\"  {key:20s}: {value:.4f}\")\n",
        "            else:\n",
        "                print(f\"  {key:20s}: {value}\")\n",
        "    else:\n",
        "        print(json.dumps(data, indent=2)[:500])  # Show first 500 chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a3WRhM94t9M"
      },
      "source": [
        "## 8Ô∏è‚É£ Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABCDKmJN4t9M"
      },
      "outputs": [],
      "source": [
        "# Package all results\n",
        "!zip -r esa_nmt_results.zip ./outputs ./checkpoints ./models -x \"*.git*\"\n",
        "\n",
        "print(\"\\n‚úÖ Results packaged!\")\n",
        "print(\"\\nFile size:\")\n",
        "!ls -lh esa_nmt_results.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNsznz4-4t9M"
      },
      "outputs": [],
      "source": [
        "# Download results\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üì• Downloading results...\")\n",
        "files.download('esa_nmt_results.zip')\n",
        "\n",
        "print(\"‚úÖ Download started! Check your browser's downloads folder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkHRPrxi4t9M"
      },
      "source": [
        "## üéØ Next Steps\n",
        "\n",
        "1. ‚úÖ Download `esa_nmt_results.zip` (button above)\n",
        "2. ‚úÖ Extract and review results\n",
        "3. ‚úÖ Check metrics in `outputs/*.json`\n",
        "4. ‚úÖ View visualizations in `outputs/*.png`\n",
        "5. ‚úÖ Use checkpoints in `checkpoints/*.pt` for further experiments\n",
        "\n",
        "### Optional: Deploy to Hugging Face\n",
        "\n",
        "```python\n",
        "!pip install huggingface_hub\n",
        "!huggingface-cli login\n",
        "!python deploy_to_huggingface.py --model_type nllb --translation_pair bn-hi --hf_username YOUR_USERNAME\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Expected Results (With PROPER Annotations)\n",
        "\n",
        "**Translation Quality:**\n",
        "- BLEU: 25-35 (good), 35+ (excellent)\n",
        "- METEOR: 40-50\n",
        "- ROUGE-L: 45-55\n",
        "- chrF: 50-60\n",
        "\n",
        "**Specialized Metrics (REALISTIC VALUES):**\n",
        "- **Emotion Accuracy: 73-78%** (NOT 99%!)\n",
        "- **Semantic Score: 0.79-0.87** (NOT 0.99!)\n",
        "\n",
        "‚ö†Ô∏è **IMPORTANT**: If you see 99% emotion accuracy or 0.99 semantic scores, you are using **random/incorrect labels**!\n",
        "\n",
        "‚úÖ **Realistic values (70-80%) are CORRECT and publishable!**\n",
        "\n",
        "---\n",
        "\n",
        "## üö® Troubleshooting\n",
        "\n",
        "**Getting 99% accuracy (too high)?**\n",
        "- Make sure you ran the annotation cell (4.5Ô∏è‚É£)\n",
        "- Verify `BHT25_All_annotated.csv` exists\n",
        "- Check that you're using `BHT25AnnotatedDataset` (not `BHT25Dataset`)\n",
        "\n",
        "**Colab disconnecting when switching tabs?**\n",
        "- Run this in browser console (F12):\n",
        "  ```javascript\n",
        "  function KeepAlive(){\n",
        "    console.log(\"Keeping alive at \" + new Date().toTimeString());\n",
        "    document.querySelector(\"colab-connect-button\").click();\n",
        "  }\n",
        "  setInterval(KeepAlive, 60000);\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "**‚úÖ Experiment Complete! Thank you for using ESA-NMT.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za24kitZ4t9N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "print(\"\\nüìÅ Generated Files:\\n\")\n",
        "\n",
        "for directory in ['./outputs', './checkpoints', './models']:\n",
        "    if os.path.exists(directory):\n",
        "        print(f\"\\n{directory}:\")\n",
        "        for root, dirs, files in os.walk(directory):\n",
        "            for file in files:\n",
        "                if not file.startswith('.'):\n",
        "                    filepath = os.path.join(root, file)\n",
        "                    size = os.path.getsize(filepath) / (1024*1024)  # MB\n",
        "                    print(f\"  - {file} ({size:.2f} MB)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw5dxFkJ4t9P"
      },
      "source": [
        "## üéØ Next Steps\n",
        "\n",
        "1. ‚úÖ Download `esa_nmt_results.zip` (button above)\n",
        "2. ‚úÖ Extract and review results\n",
        "3. ‚úÖ Check metrics in `outputs/*.json`\n",
        "4. ‚úÖ View visualizations in `outputs/*.png`\n",
        "5. ‚úÖ Use checkpoints in `checkpoints/*.pt` for further experiments\n",
        "\n",
        "### Optional: Deploy to Hugging Face\n",
        "\n",
        "```python\n",
        "!pip install huggingface_hub\n",
        "!huggingface-cli login\n",
        "!python deploy_to_huggingface.py --model_type nllb --translation_pair bn-hi --hf_username YOUR_USERNAME\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Expected Results\n",
        "\n",
        "**Translation Quality:**\n",
        "- BLEU: 25-35 (good), 35+ (excellent)\n",
        "- METEOR: 40-50\n",
        "- ROUGE-L: 45-55\n",
        "- chrF: 50-60\n",
        "\n",
        "**Specialized Metrics:**\n",
        "- Emotion Accuracy: 70-85%\n",
        "- Semantic Score: 0.80-0.90\n",
        "\n",
        "---\n",
        "\n",
        "**‚úÖ Experiment Complete! Thank you for using ESA-NMT.**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ESA-NMT: Emotion-Semantic-Aware Neural Machine Translation",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}