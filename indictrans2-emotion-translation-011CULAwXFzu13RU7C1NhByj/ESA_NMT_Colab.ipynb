{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb8IF8JJ7sOk"
      },
      "source": [
        "# ESA-NMT: Emotion-Semantic-Aware Neural Machine Translation\n",
        "\n",
        "**Bengali-Hindi-Telugu Translation with Emotion and Semantic Awareness**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SSanpui/ESA-NMT/blob/claude/indictrans2-emotion-translation-011CULAwXFzu13RU7C1NhByj/ESA_NMT_Colab.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Before You Start\n",
        "\n",
        "**Required:**\n",
        "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí **GPU**\n",
        "2. **Choose GPU**: T4 (free), V100/A100 (Pro)\n",
        "\n",
        "**Estimated Runtime:**\n",
        "- Quick Demo: 30-45 minutes (T4) / 15-20 minutes (V100)\n",
        "- Full Training: 3-4 hours (T4) / 1.5-2 hours (V100)\n",
        "- Complete Pipeline: 6-8 hours (T4) / 3-4 hours (V100)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhsG4V3G7sOw"
      },
      "source": [
        "## üîß Configuration\n",
        "\n",
        "**Choose what to run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ap6zKRK_7sOz",
        "outputId": "45db23f6-5e31-48f7-f8e7-e77e9fb1a523",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Configuration:\n",
            "  - Mode: quick_demo\n",
            "  - Translation Pair: bn-hi\n",
            "  - Model Type: nllb\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ===== CONFIGURATION =====\n",
        "# Change these settings based on what you want to run\n",
        "\n",
        "RUN_MODE = \"quick_demo\"  # Options: \"quick_demo\", \"full_training\", \"ablation\", \"tuning\", \"complete\"\n",
        "TRANSLATION_PAIR = \"bn-hi\"  # Options: \"bn-hi\", \"bn-te\"\n",
        "MODEL_TYPE = \"nllb\"  # Options: \"nllb\", \"indictrans2\"\n",
        "\n",
        "print(f\"\"\"\\n{'='*60}\n",
        "Configuration:\n",
        "  - Mode: {RUN_MODE}\n",
        "  - Translation Pair: {TRANSLATION_PAIR}\n",
        "  - Model Type: {MODEL_TYPE}\n",
        "{'='*60}\\n\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpqHd6XI7sO3"
      },
      "source": [
        "## 1Ô∏è‚É£ Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WrpSaTkC7sO4",
        "outputId": "0c61799b-7a62-4af9-f91b-a440da6500ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GPU Available: NVIDIA A100-SXM4-40GB\n",
            "‚úÖ GPU Memory: 39.6 GB\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WARNING: No GPU detected!\")\n",
        "    print(\"   Go to: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrTh7WJ77sO6"
      },
      "source": [
        "## 2Ô∏è‚É£ Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mOg1uFPR7sO8",
        "outputId": "a618df8e-ee5b-4d8c-a48a-6e51ca05331b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ESA-NMT'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 75 (delta 21), reused 49 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (75/75), 2.59 MiB | 20.28 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n",
            "/content/ESA-NMT\n",
            "Branch 'claude/indictrans2-emotion-translation-011CULAwXFzu13RU7C1NhByj' set up to track remote branch 'claude/indictrans2-emotion-translation-011CULAwXFzu13RU7C1NhByj' from 'origin'.\n",
            "Switched to a new branch 'claude/indictrans2-emotion-translation-011CULAwXFzu13RU7C1NhByj'\n",
            "‚úÖ Repository cloned and ready!\n"
          ]
        }
      ],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/SSanpui/ESA-NMT.git\n",
        "%cd ESA-NMT\n",
        "!git checkout claude/indictrans2-emotion-translation-011CULAwXFzu13RU7C1NhByj\n",
        "\n",
        "print(\"‚úÖ Repository cloned and ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjBCZxrf7sO-"
      },
      "source": [
        "## 3Ô∏è‚É£ Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_2n6VGFE7sPA",
        "outputId": "3fc069e6-340f-43e8-bc9f-668992eb54f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers>=4.30.0 sentence-transformers>=2.2.0 sacrebleu>=2.3.0 \\\n",
        "    rouge-score>=0.1.2 accelerate>=0.20.0 datasets>=2.12.0\n",
        "\n",
        "# Install NLTK data\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "print(\"‚úÖ All dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ535XUb7sPC"
      },
      "source": [
        "## 4Ô∏è‚É£ Verify Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TqUXO-tj7sPD",
        "outputId": "92a8f1f0-ec7a-462f-86d0-7808b419623f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset loaded: 27149 parallel sentences\n",
            "   Languages: ['bn', 'hi', 'te']\n",
            "\n",
            "üìù Sample data:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                  bn  \\\n",
              "0  ‡¶π‡ßÅ‡¶ó‡¶≤‡¶ø ‡¶ú‡ßá‡¶≤‡¶æ‡¶∞ ‡¶∏‡¶™‡ßç‡¶§‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ‡ßá ‡¶¶‡ßÅ‡¶á ‡¶≠‡¶æ‡¶á ‡¶®‡ßÄ‡¶≤‡¶æ‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶ì ‡¶™‡ßÄ‡¶§‡¶æ...   \n",
              "1  ‡¶ì ‡¶Ö‡¶û‡ßç‡¶ö‡¶≤‡ßá ‡¶®‡ßÄ‡¶≤‡¶æ‡¶Æ‡ßç‡¶¨‡¶∞‡ßá‡¶∞ ‡¶Æ‡¶§ ‡¶Æ‡ßú‡¶æ ‡¶™‡ßã‡ßú‡¶æ‡¶á‡¶§‡ßá, ‡¶ï‡ßÄ‡¶∞‡ßç‡¶§‡¶® ‡¶ó‡¶æ‡¶π...   \n",
              "2         ‡¶§‡¶æ‡¶π‡¶æ‡¶∞ ‡¶â‡¶®‡ßç‡¶®‡¶§ ‡¶ó‡ßå‡¶∞‡¶¨‡¶∞‡ßç‡¶£ ‡¶¶‡ßá‡¶π‡ßá ‡¶Ö‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶∂‡¶ï‡ßç‡¶§‡¶ø ‡¶õ‡¶ø‡¶≤   \n",
              "\n",
              "                                                  hi  \\\n",
              "0  ‡§π‡•Å‡§ó‡§≤‡•Ä ‡§ú‡§ø‡§≤‡•á ‡§ï‡§æ ‡§∏‡§™‡•ç‡§§‡§ó‡•ç‡§∞‡§æ‡§Æ-‡§â‡§∏‡§Æ‡•á‡§Ç ‡§¶‡•ã ‡§≠‡§æ‡§à ‡§®‡•Ä‡§≤‡§æ‡§Æ‡•ç‡§¨‡§∞ ...   \n",
              "1  ‡§®‡•Ä‡§≤‡§æ‡§Æ‡•ç‡§¨‡§∞ ‡§Æ‡•Å‡§∞‡•ç‡§¶‡•á ‡§ú‡§≤‡§æ‡§®‡•á, ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® ‡§ï‡§∞‡§®‡•á, ‡§¢‡•ã‡§≤ ‡§¨‡§ú‡§æ‡§®‡•á ...   \n",
              "2  ‡§â‡§∏‡§ï‡§æ ‡§ï‡§¶ ‡§≤‡§Æ‡•ç‡§¨‡§æ, ‡§¨‡§¶‡§® ‡§ó‡•ã‡§∞‡§æ, ‡§¨‡§π‡•Å‡§§ ‡§π‡•Ä ‡§ö‡•Å‡§∏‡•ç‡§§, ‡§´‡•Å‡§∞‡•ç‡§§‡•Ä...   \n",
              "\n",
              "                                                  te  \n",
              "0  ‡∞π‡±Å‡∞ó‡±ç‡∞≤‡±Ä ‡∞ú‡∞ø‡∞≤‡±ç‡∞≤‡∞æ‡∞≤‡±ã‡∞®‡∞ø ‡∞∏‡∞™‡±ç‡∞§‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡±ç-‡∞¶‡±Ä‡∞®‡∞ø‡∞ï‡∞ø ‡∞á‡∞¶‡±ç‡∞¶‡∞∞‡±Å ‡∞∏‡±ã‡∞¶...  \n",
              "1  ‡∞Æ‡±É‡∞§‡∞¶‡±á‡∞π‡∞æ‡∞≤‡∞®‡±Å ‡∞¶‡∞π‡∞®‡∞Ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç‡∞≤‡±ã, ‡∞ï‡±Ä‡∞∞‡±ç‡∞§‡∞®‡∞≤‡±Å ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç‡∞≤‡±ã, ‡∞°‡±ç‡∞∞...  \n",
              "2  ‡∞Ö‡∞§‡∞®‡±Å ‡∞™‡±ä‡∞°‡∞µ‡±à‡∞®‡∞µ‡∞æ‡∞°‡±Å, ‡∞§‡±Ü‡∞≤‡±ç‡∞≤‡∞®‡∞ø ‡∞ö‡∞∞‡±ç‡∞Æ‡∞Ç ‡∞ó‡∞≤‡∞µ‡∞æ‡∞°‡±Å, ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞ö‡±Å...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d4e262f-c84c-402a-822f-de7119ebc028\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bn</th>\n",
              "      <th>hi</th>\n",
              "      <th>te</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‡¶π‡ßÅ‡¶ó‡¶≤‡¶ø ‡¶ú‡ßá‡¶≤‡¶æ‡¶∞ ‡¶∏‡¶™‡ßç‡¶§‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ‡ßá ‡¶¶‡ßÅ‡¶á ‡¶≠‡¶æ‡¶á ‡¶®‡ßÄ‡¶≤‡¶æ‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶ì ‡¶™‡ßÄ‡¶§‡¶æ...</td>\n",
              "      <td>‡§π‡•Å‡§ó‡§≤‡•Ä ‡§ú‡§ø‡§≤‡•á ‡§ï‡§æ ‡§∏‡§™‡•ç‡§§‡§ó‡•ç‡§∞‡§æ‡§Æ-‡§â‡§∏‡§Æ‡•á‡§Ç ‡§¶‡•ã ‡§≠‡§æ‡§à ‡§®‡•Ä‡§≤‡§æ‡§Æ‡•ç‡§¨‡§∞ ...</td>\n",
              "      <td>‡∞π‡±Å‡∞ó‡±ç‡∞≤‡±Ä ‡∞ú‡∞ø‡∞≤‡±ç‡∞≤‡∞æ‡∞≤‡±ã‡∞®‡∞ø ‡∞∏‡∞™‡±ç‡∞§‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡±ç-‡∞¶‡±Ä‡∞®‡∞ø‡∞ï‡∞ø ‡∞á‡∞¶‡±ç‡∞¶‡∞∞‡±Å ‡∞∏‡±ã‡∞¶...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‡¶ì ‡¶Ö‡¶û‡ßç‡¶ö‡¶≤‡ßá ‡¶®‡ßÄ‡¶≤‡¶æ‡¶Æ‡ßç‡¶¨‡¶∞‡ßá‡¶∞ ‡¶Æ‡¶§ ‡¶Æ‡ßú‡¶æ ‡¶™‡ßã‡ßú‡¶æ‡¶á‡¶§‡ßá, ‡¶ï‡ßÄ‡¶∞‡ßç‡¶§‡¶® ‡¶ó‡¶æ‡¶π...</td>\n",
              "      <td>‡§®‡•Ä‡§≤‡§æ‡§Æ‡•ç‡§¨‡§∞ ‡§Æ‡•Å‡§∞‡•ç‡§¶‡•á ‡§ú‡§≤‡§æ‡§®‡•á, ‡§ï‡•Ä‡§∞‡•ç‡§§‡§® ‡§ï‡§∞‡§®‡•á, ‡§¢‡•ã‡§≤ ‡§¨‡§ú‡§æ‡§®‡•á ...</td>\n",
              "      <td>‡∞Æ‡±É‡∞§‡∞¶‡±á‡∞π‡∞æ‡∞≤‡∞®‡±Å ‡∞¶‡∞π‡∞®‡∞Ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç‡∞≤‡±ã, ‡∞ï‡±Ä‡∞∞‡±ç‡∞§‡∞®‡∞≤‡±Å ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç‡∞≤‡±ã, ‡∞°‡±ç‡∞∞...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‡¶§‡¶æ‡¶π‡¶æ‡¶∞ ‡¶â‡¶®‡ßç‡¶®‡¶§ ‡¶ó‡ßå‡¶∞‡¶¨‡¶∞‡ßç‡¶£ ‡¶¶‡ßá‡¶π‡ßá ‡¶Ö‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶∂‡¶ï‡ßç‡¶§‡¶ø ‡¶õ‡¶ø‡¶≤</td>\n",
              "      <td>‡§â‡§∏‡§ï‡§æ ‡§ï‡§¶ ‡§≤‡§Æ‡•ç‡§¨‡§æ, ‡§¨‡§¶‡§® ‡§ó‡•ã‡§∞‡§æ, ‡§¨‡§π‡•Å‡§§ ‡§π‡•Ä ‡§ö‡•Å‡§∏‡•ç‡§§, ‡§´‡•Å‡§∞‡•ç‡§§‡•Ä...</td>\n",
              "      <td>‡∞Ö‡∞§‡∞®‡±Å ‡∞™‡±ä‡∞°‡∞µ‡±à‡∞®‡∞µ‡∞æ‡∞°‡±Å, ‡∞§‡±Ü‡∞≤‡±ç‡∞≤‡∞®‡∞ø ‡∞ö‡∞∞‡±ç‡∞Æ‡∞Ç ‡∞ó‡∞≤‡∞µ‡∞æ‡∞°‡±Å, ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞ö‡±Å...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d4e262f-c84c-402a-822f-de7119ebc028')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0d4e262f-c84c-402a-822f-de7119ebc028 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0d4e262f-c84c-402a-822f-de7119ebc028');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-599a22ba-2dde-45d7-acd2-24323fa12535\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-599a22ba-2dde-45d7-acd2-24323fa12535')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-599a22ba-2dde-45d7-acd2-24323fa12535 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\u274c Dataset not found!\\\")\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"bn\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\\u09b9\\u09c1\\u0997\\u09b2\\u09bf \\u099c\\u09c7\\u09b2\\u09be\\u09b0 \\u09b8\\u09aa\\u09cd\\u09a4\\u0997\\u09cd\\u09b0\\u09be\\u09ae\\u09c7 \\u09a6\\u09c1\\u0987 \\u09ad\\u09be\\u0987 \\u09a8\\u09c0\\u09b2\\u09be\\u09ae\\u09cd\\u09ac\\u09b0 \\u0993 \\u09aa\\u09c0\\u09a4\\u09be\\u09ae\\u09cd\\u09ac\\u09b0 \\u099a\\u0995\\u09cd\\u09b0\\u09ac\\u09b0\\u09cd\\u09a4\\u09c0 \\u09ac\\u09be\\u09b8 \\u0995\\u09b0\\u09bf\\u09a4\",\n          \"\\u0993 \\u0985\\u099e\\u09cd\\u099a\\u09b2\\u09c7 \\u09a8\\u09c0\\u09b2\\u09be\\u09ae\\u09cd\\u09ac\\u09b0\\u09c7\\u09b0 \\u09ae\\u09a4 \\u09ae\\u09dc\\u09be \\u09aa\\u09cb\\u09dc\\u09be\\u0987\\u09a4\\u09c7, \\u0995\\u09c0\\u09b0\\u09cd\\u09a4\\u09a8 \\u0997\\u09be\\u09b9\\u09bf\\u09a4\\u09c7, \\u0996\\u09cb\\u09b2 \\u09ac\\u09be\\u099c\\u09be\\u0987\\u09a4\\u09c7 \\u098f\\u09ac\\u0982 \\u0997\\u09be\\u0981\\u099c\\u09be \\u0996\\u09be\\u0987\\u09a4\\u09c7 \\u0995\\u09c7\\u09b9 \\u09aa\\u09be\\u09b0\\u09bf\\u09a4 \\u09a8\\u09be\",\n          \"\\u09a4\\u09be\\u09b9\\u09be\\u09b0 \\u0989\\u09a8\\u09cd\\u09a8\\u09a4 \\u0997\\u09cc\\u09b0\\u09ac\\u09b0\\u09cd\\u09a3 \\u09a6\\u09c7\\u09b9\\u09c7 \\u0985\\u09b8\\u09be\\u09a7\\u09be\\u09b0\\u09a3 \\u09b6\\u0995\\u09cd\\u09a4\\u09bf \\u099b\\u09bf\\u09b2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hi\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\\u0939\\u0941\\u0917\\u0932\\u0940 \\u091c\\u093f\\u0932\\u0947 \\u0915\\u093e \\u0938\\u092a\\u094d\\u0924\\u0917\\u094d\\u0930\\u093e\\u092e-\\u0909\\u0938\\u092e\\u0947\\u0902 \\u0926\\u094b \\u092d\\u093e\\u0908 \\u0928\\u0940\\u0932\\u093e\\u092e\\u094d\\u092c\\u0930 \\u0935 \\u092a\\u0940\\u0924\\u093e\\u092e\\u094d\\u092c\\u0930 \\u0930\\u0939\\u0924\\u0947 \\u0925\\u0947\",\n          \"\\u0928\\u0940\\u0932\\u093e\\u092e\\u094d\\u092c\\u0930 \\u092e\\u0941\\u0930\\u094d\\u0926\\u0947 \\u091c\\u0932\\u093e\\u0928\\u0947, \\u0915\\u0940\\u0930\\u094d\\u0924\\u0928 \\u0915\\u0930\\u0928\\u0947, \\u0922\\u094b\\u0932 \\u092c\\u091c\\u093e\\u0928\\u0947 \\u0914\\u0930 \\u0917\\u093e\\u0902\\u091c\\u0947 \\u0915\\u093e \\u0926\\u092e \\u092d\\u0930\\u0928\\u0947 \\u092e\\u0947\\u0902 \\u092c\\u0947\\u091c\\u094b\\u0921\\u093c \\u0925\\u093e\",\n          \"\\u0909\\u0938\\u0915\\u093e \\u0915\\u0926 \\u0932\\u092e\\u094d\\u092c\\u093e, \\u092c\\u0926\\u0928 \\u0917\\u094b\\u0930\\u093e, \\u092c\\u0939\\u0941\\u0924 \\u0939\\u0940 \\u091a\\u0941\\u0938\\u094d\\u0924, \\u092b\\u0941\\u0930\\u094d\\u0924\\u0940\\u0932\\u093e \\u0924\\u0925\\u093e \\u0924\\u093e\\u0915\\u0924\\u0935\\u0930 \\u0925\\u093e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"te\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\\u0c39\\u0c41\\u0c17\\u0c4d\\u0c32\\u0c40 \\u0c1c\\u0c3f\\u0c32\\u0c4d\\u0c32\\u0c3e\\u0c32\\u0c4b\\u0c28\\u0c3f \\u0c38\\u0c2a\\u0c4d\\u0c24\\u0c17\\u0c4d\\u0c30\\u0c3e\\u0c2e\\u0c4d-\\u0c26\\u0c40\\u0c28\\u0c3f\\u0c15\\u0c3f \\u0c07\\u0c26\\u0c4d\\u0c26\\u0c30\\u0c41 \\u0c38\\u0c4b\\u0c26\\u0c30\\u0c41\\u0c32\\u0c41 \\u0c28\\u0c40\\u0c32\\u0c3e\\u0c02\\u0c2c\\u0c30\\u0c4d \\u0c2e\\u0c30\\u0c3f\\u0c2f\\u0c41 \\u0c2a\\u0c3f\\u0c24\\u0c3e\\u0c02\\u0c2c\\u0c30\\u0c4d \\u0c05\\u0c15\\u0c4d\\u0c15\\u0c21 \\u0c28\\u0c3f\\u0c35\\u0c38\\u0c3f\\u0c02\\u0c1a\\u0c47\\u0c35\\u0c3e\\u0c30\\u0c41.\",\n          \"\\u0c2e\\u0c43\\u0c24\\u0c26\\u0c47\\u0c39\\u0c3e\\u0c32\\u0c28\\u0c41 \\u0c26\\u0c39\\u0c28\\u0c02 \\u0c1a\\u0c47\\u0c2f\\u0c21\\u0c02\\u0c32\\u0c4b, \\u0c15\\u0c40\\u0c30\\u0c4d\\u0c24\\u0c28\\u0c32\\u0c41 \\u0c1a\\u0c47\\u0c2f\\u0c21\\u0c02\\u0c32\\u0c4b, \\u0c21\\u0c4d\\u0c30\\u0c2e\\u0c4d\\u0c38\\u0c4d \\u0c35\\u0c3e\\u0c2f\\u0c3f\\u0c02\\u0c1a\\u0c21\\u0c02\\u0c32\\u0c4b \\u0c2e\\u0c30\\u0c3f\\u0c2f\\u0c41 \\u0c17\\u0c02\\u0c1c\\u0c3e\\u0c2f\\u0c3f \\u0c15\\u0c3e\\u0c32\\u0c4d\\u0c1a\\u0c21\\u0c02\\u0c32\\u0c4b \\u0c28\\u0c40\\u0c32\\u0c3e\\u0c02\\u0c2c\\u0c30\\u0c4d \\u0c38\\u0c3e\\u0c1f\\u0c3f\\u0c32\\u0c47\\u0c28\\u0c3f\\u0c35\\u0c3e\\u0c21\\u0c41.\",\n          \"\\u0c05\\u0c24\\u0c28\\u0c41 \\u0c2a\\u0c4a\\u0c21\\u0c35\\u0c48\\u0c28\\u0c35\\u0c3e\\u0c21\\u0c41, \\u0c24\\u0c46\\u0c32\\u0c4d\\u0c32\\u0c28\\u0c3f \\u0c1a\\u0c30\\u0c4d\\u0c2e\\u0c02 \\u0c17\\u0c32\\u0c35\\u0c3e\\u0c21\\u0c41, \\u0c1a\\u0c3e\\u0c32\\u0c3e \\u0c1a\\u0c41\\u0c30\\u0c41\\u0c15\\u0c48\\u0c28\\u0c35\\u0c3e\\u0c21\\u0c41, \\u0c1a\\u0c41\\u0c30\\u0c41\\u0c15\\u0c48\\u0c28\\u0c35\\u0c3e\\u0c21\\u0c41 \\u0c2e\\u0c30\\u0c3f\\u0c2f\\u0c41 \\u0c2c\\u0c32\\u0c35\\u0c02\\u0c24\\u0c41\\u0c21\\u0c41.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "if os.path.exists('BHT25_All.csv'):\n",
        "    df = pd.read_csv('BHT25_All.csv')\n",
        "    print(f\"‚úÖ Dataset loaded: {len(df)} parallel sentences\")\n",
        "    print(f\"   Languages: {df.columns.tolist()}\")\n",
        "    print(f\"\\nüìù Sample data:\")\n",
        "    display(df.head(3))\n",
        "else:\n",
        "    print(\"‚ùå Dataset not found!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üî• 4.5Ô∏è‚É£ Annotate Dataset with XLM-RoBERTa (ONE-TIME, 30-60 mins)\n",
        "\n",
        "**‚ö†Ô∏è IMPORTANT: Uses XLM-RoBERTa for cross-lingual emotion detection!**\n",
        "\n",
        "This annotation step:\n",
        "- Uses **XLM-RoBERTa-base** for zero-shot cross-lingual emotion classification\n",
        "- Supports Bengali, Hindi, and Telugu text (Indic scripts)\n",
        "- Classifies into 8 emotions: joy, sadness, anger, fear, trust, disgust, surprise, anticipation\n",
        "- Uses LaBSE for semantic similarity (cross-lingual sentence embeddings)\n",
        "\n",
        "**Expected emotion distribution:**\n",
        "- 28% joy (celebratory scenes, romantic moments)\n",
        "- 22% sadness (tragic events, separation)\n",
        "- 15% anger (conflict scenes)\n",
        "- 13% fear (suspenseful moments)\n",
        "- 22% others (surprise, trust, disgust, anticipation)\n",
        "\n",
        "**Skip this cell if `BHT25_All_annotated.csv` already exists!**"
      ],
      "metadata": {
        "id": "pw8g-RXe7sPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if already annotated\n",
        "if os.path.exists('BHT25_All_annotated.csv'):\n",
        "    print(\"‚úÖ Annotated dataset already exists!\")\n",
        "    print(\"   Skipping annotation step...\")\n",
        "\n",
        "    # Show annotation stats\n",
        "    df_annotated = pd.read_csv('BHT25_All_annotated.csv')\n",
        "    print(f\"\\nüìä Annotation Statistics:\")\n",
        "    print(f\"   Total samples: {len(df_annotated)}\")\n",
        "    print(f\"   Columns: {df_annotated.columns.tolist()}\")\n",
        "\n",
        "    # Emotion distribution\n",
        "    if 'emotion_bn' in df_annotated.columns:\n",
        "        emotion_names = ['joy', 'sadness', 'anger', 'fear', 'trust', 'disgust', 'surprise', 'anticipation']\n",
        "        print(f\"\\n   Emotion distribution (Bengali):\")\n",
        "        for i in range(8):\n",
        "            count = (df_annotated['emotion_bn'] == i).sum()\n",
        "            pct = count / len(df_annotated) * 100\n",
        "            print(f\"     {emotion_names[i]:12s}: {count:4d} ({pct:5.1f}%)\")\n",
        "\n",
        "    # Semantic scores\n",
        "    if 'semantic_bn_hi' in df_annotated.columns:\n",
        "        print(f\"\\n   Semantic similarity (bn-hi):\")\n",
        "        print(f\"     Mean: {df_annotated['semantic_bn_hi'].mean():.4f}\")\n",
        "        print(f\"     Std:  {df_annotated['semantic_bn_hi'].std():.4f}\")\n",
        "\n",
        "else:\n",
        "    print(\"üîÑ Annotating dataset... (this will take 30-60 minutes)\")\n",
        "    print(\"‚è∞ Grab a coffee! This creates REAL emotion/semantic labels.\")\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Run annotation script\n",
        "    !python annotate_dataset.py\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ Annotation complete!\")\n",
        "    print(\"   Created: BHT25_All_annotated.csv\")"
      ],
      "metadata": {
        "id": "AG4utcjC7sPH",
        "outputId": "ba91fbaa-428c-47d4-a5d3-6124b65f0b05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Annotating dataset... (this will take 30-60 minutes)\n",
            "‚è∞ Grab a coffee! This creates REAL emotion/semantic labels.\n",
            "\n",
            "============================================================\n",
            "2025-10-26 14:34:46.408219: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-10-26 14:34:46.425633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761489286.447079    1048 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761489286.453549    1048 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761489286.469998    1048 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761489286.470022    1048 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761489286.470025    1048 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761489286.470028    1048 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-26 14:34:46.474659: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "üîÑ Loading annotation models...\n",
            "   Using XLM-RoBERTa-base for cross-lingual emotion detection...\n",
            "config.json: 100% 734/734 [00:00<00:00, 7.04MB/s]\n",
            "model.safetensors: 100% 2.24G/2.24G [00:12<00:00, 184MB/s]\n",
            "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 273kB/s]\n",
            "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 223MB/s]\n",
            "special_tokens_map.json: 100% 150/150 [00:00<00:00, 1.75MB/s]\n",
            "Device set to use cuda:0\n",
            "modules.json: 100% 461/461 [00:00<00:00, 5.31MB/s]\n",
            "config_sentence_transformers.json: 100% 122/122 [00:00<00:00, 1.29MB/s]\n",
            "README.md: 2.02kB [00:00, 11.9MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 648kB/s]\n",
            "config.json: 100% 804/804 [00:00<00:00, 9.66MB/s]\n",
            "model.safetensors: 100% 1.88G/1.88G [00:08<00:00, 218MB/s]\n",
            "tokenizer_config.json: 100% 397/397 [00:00<00:00, 1.11MB/s]\n",
            "vocab.txt: 5.22MB [00:00, 112MB/s]\n",
            "tokenizer.json: 9.62MB [00:00, 130MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 720kB/s]\n",
            "config.json: 100% 190/190 [00:00<00:00, 2.34MB/s]\n",
            "config.json: 100% 114/114 [00:00<00:00, 1.19MB/s]\n",
            "2_Dense/model.safetensors: 100% 2.36M/2.36M [00:00<00:00, 4.49MB/s]\n",
            "‚úÖ Models loaded!\n",
            "\n",
            "üìÇ Loading dataset from: BHT25_All.csv\n",
            "Dataset shape: (27149, 3)\n",
            "Columns: ['bn', 'hi', 'te']\n",
            "After removing NaN: (27147, 3)\n",
            "\n",
            "üîÑ Annotating dataset (this may take a while)...\n",
            "  0% 3/27147 [00:01<4:17:43,  1.76it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  0% 99/27147 [00:40<3:01:32,  2.48it/s]Processed 100 rows...\n",
            "  1% 199/27147 [01:20<2:58:03,  2.52it/s]Processed 200 rows...\n",
            "  1% 299/27147 [02:00<3:00:35,  2.48it/s]Processed 300 rows...\n",
            "  1% 399/27147 [02:39<2:56:42,  2.52it/s]Processed 400 rows...\n",
            "  2% 499/27147 [03:19<2:58:04,  2.49it/s]Processed 500 rows...\n",
            "  2% 599/27147 [03:59<2:58:27,  2.48it/s]Processed 600 rows...\n",
            "  3% 699/27147 [04:39<2:55:58,  2.50it/s]Processed 700 rows...\n",
            "  3% 799/27147 [05:19<2:54:56,  2.51it/s]Processed 800 rows...\n",
            "  3% 899/27147 [05:59<2:54:16,  2.51it/s]Processed 900 rows...\n",
            "  4% 999/27147 [06:39<2:54:47,  2.49it/s]Processed 1000 rows...\n",
            "  4% 1099/27147 [07:18<2:54:15,  2.49it/s]Processed 1100 rows...\n",
            "  4% 1199/27147 [07:58<2:53:37,  2.49it/s]Processed 1200 rows...\n",
            "  5% 1299/27147 [08:38<2:52:19,  2.50it/s]Processed 1300 rows...\n",
            "  5% 1399/27147 [09:19<2:55:04,  2.45it/s]Processed 1400 rows...\n",
            "  6% 1499/27147 [09:59<2:50:47,  2.50it/s]Processed 1500 rows...\n",
            "  6% 1599/27147 [10:39<2:47:42,  2.54it/s]Processed 1600 rows...\n",
            "  6% 1699/27147 [11:19<2:49:43,  2.50it/s]Processed 1700 rows...\n",
            "  7% 1799/27147 [11:59<2:49:42,  2.49it/s]Processed 1800 rows...\n",
            "  7% 1899/27147 [12:39<2:47:59,  2.50it/s]Processed 1900 rows...\n",
            "  7% 1999/27147 [13:19<2:48:31,  2.49it/s]Processed 2000 rows...\n",
            "  8% 2099/27147 [13:59<2:07:56,  3.26it/s]Processed 2100 rows...\n",
            "  8% 2199/27147 [14:39<2:46:21,  2.50it/s]Processed 2200 rows...\n",
            "  8% 2299/27147 [15:19<2:46:21,  2.49it/s]Processed 2300 rows...\n",
            "  9% 2399/27147 [16:00<2:46:24,  2.48it/s]Processed 2400 rows...\n",
            "  9% 2499/27147 [16:40<2:47:50,  2.45it/s]Processed 2500 rows...\n",
            " 10% 2599/27147 [17:20<2:44:21,  2.49it/s]Processed 2600 rows...\n",
            " 10% 2699/27147 [18:01<2:47:02,  2.44it/s]Processed 2700 rows...\n",
            " 10% 2799/27147 [18:41<2:43:00,  2.49it/s]Processed 2800 rows...\n",
            " 11% 2899/27147 [19:20<2:45:10,  2.45it/s]Processed 2900 rows...\n",
            " 11% 2999/27147 [20:01<2:41:12,  2.50it/s]Processed 3000 rows...\n",
            " 11% 3099/27147 [20:41<2:43:33,  2.45it/s]Processed 3100 rows...\n",
            " 12% 3199/27147 [21:21<2:39:53,  2.50it/s]Processed 3200 rows...\n",
            " 12% 3299/27147 [22:01<2:38:34,  2.51it/s]Processed 3300 rows...\n",
            " 13% 3399/27147 [22:41<2:38:39,  2.49it/s]Processed 3400 rows...\n",
            " 13% 3499/27147 [23:21<2:40:14,  2.46it/s]Processed 3500 rows...\n",
            " 13% 3599/27147 [24:01<2:37:25,  2.49it/s]Processed 3600 rows...\n",
            " 14% 3699/27147 [24:41<2:38:34,  2.46it/s]Processed 3700 rows...\n",
            " 14% 3799/27147 [25:22<2:35:03,  2.51it/s]Processed 3800 rows...\n",
            " 14% 3899/27147 [26:02<2:35:23,  2.49it/s]Processed 3900 rows...\n",
            " 15% 3999/27147 [26:42<2:34:01,  2.50it/s]Processed 4000 rows...\n",
            " 15% 4099/27147 [27:22<2:34:08,  2.49it/s]Processed 4100 rows...\n",
            " 15% 4199/27147 [28:02<2:32:42,  2.50it/s]Processed 4200 rows...\n",
            " 16% 4299/27147 [28:42<2:33:59,  2.47it/s]Processed 4300 rows...\n",
            " 16% 4399/27147 [29:22<2:32:15,  2.49it/s]Processed 4400 rows...\n",
            " 17% 4499/27147 [30:02<2:32:22,  2.48it/s]Processed 4500 rows...\n",
            " 17% 4599/27147 [30:42<2:30:24,  2.50it/s]Processed 4600 rows...\n",
            " 17% 4699/27147 [31:22<2:31:03,  2.48it/s]Processed 4700 rows...\n",
            " 18% 4799/27147 [32:02<2:29:22,  2.49it/s]Processed 4800 rows...\n",
            " 18% 4899/27147 [32:42<2:29:09,  2.49it/s]Processed 4900 rows...\n",
            " 18% 4999/27147 [33:22<2:28:22,  2.49it/s]Processed 5000 rows...\n",
            " 19% 5099/27147 [34:02<2:29:46,  2.45it/s]Processed 5100 rows...\n",
            " 19% 5199/27147 [34:42<2:26:05,  2.50it/s]Processed 5200 rows...\n",
            " 20% 5299/27147 [35:22<2:25:09,  2.51it/s]Processed 5300 rows...\n",
            " 20% 5399/27147 [36:02<2:24:55,  2.50it/s]Processed 5400 rows...\n",
            " 20% 5499/27147 [36:42<2:25:20,  2.48it/s]Processed 5500 rows...\n",
            " 21% 5599/27147 [37:22<2:25:02,  2.48it/s]Processed 5600 rows...\n",
            " 21% 5699/27147 [38:02<2:23:30,  2.49it/s]Processed 5700 rows...\n",
            " 21% 5799/27147 [38:42<2:21:14,  2.52it/s]Processed 5800 rows...\n",
            " 22% 5899/27147 [39:22<2:21:46,  2.50it/s]Processed 5900 rows...\n",
            " 22% 5999/27147 [40:03<2:23:47,  2.45it/s]Processed 6000 rows...\n",
            " 22% 6099/27147 [40:43<2:22:28,  2.46it/s]Processed 6100 rows...\n",
            " 23% 6199/27147 [41:23<2:19:17,  2.51it/s]Processed 6200 rows...\n",
            " 23% 6299/27147 [42:03<2:21:11,  2.46it/s]Processed 6300 rows...\n",
            " 24% 6399/27147 [42:43<2:17:10,  2.52it/s]Processed 6400 rows...\n",
            " 24% 6498/27147 [43:22<2:18:13,  2.49it/s]Processed 6500 rows...\n",
            " 24% 6598/27147 [44:02<2:16:06,  2.52it/s]Processed 6600 rows...\n",
            " 25% 6698/27147 [44:42<2:17:37,  2.48it/s]Processed 6700 rows...\n",
            " 25% 6798/27147 [45:22<2:15:29,  2.50it/s]Processed 6800 rows...\n",
            " 25% 6898/27147 [46:02<2:16:27,  2.47it/s]Processed 6900 rows...\n",
            " 26% 6998/27147 [46:42<2:12:35,  2.53it/s]Processed 7000 rows...\n",
            " 26% 7098/27147 [47:22<2:14:27,  2.49it/s]Processed 7100 rows...\n",
            " 27% 7198/27147 [48:03<2:12:42,  2.51it/s]Processed 7200 rows...\n",
            " 27% 7298/27147 [48:43<2:13:18,  2.48it/s]Processed 7300 rows...\n",
            " 27% 7397/27147 [49:23<2:11:36,  2.50it/s]Processed 7400 rows...\n",
            " 28% 7497/27147 [50:03<2:11:35,  2.49it/s]Processed 7500 rows...\n",
            " 28% 7597/27147 [50:43<2:09:06,  2.52it/s]Processed 7600 rows...\n",
            " 28% 7697/27147 [51:23<2:09:52,  2.50it/s]Processed 7700 rows...\n",
            " 29% 7797/27147 [52:03<2:07:24,  2.53it/s]Processed 7800 rows...\n",
            " 29% 7897/27147 [52:43<2:07:56,  2.51it/s]Processed 7900 rows...\n",
            " 29% 7997/27147 [53:23<2:06:49,  2.52it/s]Processed 8000 rows...\n",
            " 30% 8097/27147 [54:03<2:07:31,  2.49it/s]Processed 8100 rows...\n",
            " 30% 8197/27147 [54:43<2:05:41,  2.51it/s]Processed 8200 rows...\n",
            " 31% 8297/27147 [55:23<2:06:18,  2.49it/s]Processed 8300 rows...\n",
            " 31% 8397/27147 [56:03<2:05:23,  2.49it/s]Processed 8400 rows...\n",
            " 31% 8497/27147 [56:43<2:05:34,  2.48it/s]Processed 8500 rows...\n",
            " 32% 8597/27147 [57:23<2:03:14,  2.51it/s]Processed 8600 rows...\n",
            " 32% 8697/27147 [58:03<2:02:51,  2.50it/s]Processed 8700 rows...\n",
            " 32% 8797/27147 [58:43<2:01:05,  2.53it/s]Processed 8800 rows...\n",
            " 33% 8897/27147 [59:23<2:02:31,  2.48it/s]Processed 8900 rows...\n",
            " 33% 8997/27147 [1:00:03<2:00:27,  2.51it/s]Processed 9000 rows...\n",
            " 34% 9097/27147 [1:00:43<2:00:26,  2.50it/s]Processed 9100 rows...\n",
            " 34% 9197/27147 [1:01:23<1:59:08,  2.51it/s]Processed 9200 rows...\n",
            " 34% 9297/27147 [1:02:03<1:59:43,  2.48it/s]Processed 9300 rows...\n",
            " 35% 9397/27147 [1:02:44<2:00:29,  2.46it/s]Processed 9400 rows...\n",
            " 35% 9497/27147 [1:03:25<1:59:16,  2.47it/s]Processed 9500 rows...\n",
            " 35% 9597/27147 [1:04:05<1:56:51,  2.50it/s]Processed 9600 rows...\n",
            " 36% 9697/27147 [1:04:45<1:56:21,  2.50it/s]Processed 9700 rows...\n",
            " 36% 9797/27147 [1:05:25<1:54:40,  2.52it/s]Processed 9800 rows...\n",
            " 36% 9897/27147 [1:06:05<1:54:49,  2.50it/s]Processed 9900 rows...\n",
            " 37% 9997/27147 [1:06:45<1:54:23,  2.50it/s]Processed 10000 rows...\n",
            " 37% 10097/27147 [1:07:25<1:53:31,  2.50it/s]Processed 10100 rows...\n",
            " 38% 10197/27147 [1:08:05<1:52:01,  2.52it/s]Processed 10200 rows...\n",
            " 38% 10297/27147 [1:08:45<1:53:19,  2.48it/s]Processed 10300 rows...\n",
            " 38% 10397/27147 [1:09:26<1:51:21,  2.51it/s]Processed 10400 rows...\n",
            " 39% 10497/27147 [1:10:06<1:50:15,  2.52it/s]Processed 10500 rows...\n",
            " 39% 10597/27147 [1:10:46<1:50:03,  2.51it/s]Processed 10600 rows...\n",
            " 39% 10697/27147 [1:11:26<1:49:44,  2.50it/s]Processed 10700 rows...\n",
            " 40% 10797/27147 [1:12:06<1:48:02,  2.52it/s]Processed 10800 rows...\n",
            " 40% 10897/27147 [1:12:46<1:49:25,  2.48it/s]Processed 10900 rows...\n",
            " 41% 10997/27147 [1:13:27<1:50:01,  2.45it/s]Processed 11000 rows...\n",
            " 41% 11097/27147 [1:14:08<1:47:44,  2.48it/s]Processed 11100 rows...\n",
            " 41% 11197/27147 [1:14:48<1:46:28,  2.50it/s]Processed 11200 rows...\n",
            " 42% 11297/27147 [1:15:29<1:45:32,  2.50it/s]Processed 11300 rows...\n",
            " 42% 11397/27147 [1:16:09<1:45:06,  2.50it/s]Processed 11400 rows...\n",
            " 42% 11497/27147 [1:16:49<1:43:34,  2.52it/s]Processed 11500 rows...\n",
            " 43% 11597/27147 [1:17:29<1:44:29,  2.48it/s]Processed 11600 rows...\n",
            " 43% 11697/27147 [1:18:10<1:43:01,  2.50it/s]Processed 11700 rows...\n",
            " 43% 11797/27147 [1:18:50<1:43:41,  2.47it/s]Processed 11800 rows...\n",
            " 44% 11897/27147 [1:19:30<1:41:06,  2.51it/s]Processed 11900 rows...\n",
            " 44% 11997/27147 [1:20:11<1:41:01,  2.50it/s]Processed 12000 rows...\n",
            " 45% 12097/27147 [1:20:51<1:40:21,  2.50it/s]Processed 12100 rows...\n",
            " 45% 12197/27147 [1:21:31<1:40:08,  2.49it/s]Processed 12200 rows...\n",
            " 45% 12297/27147 [1:22:11<1:38:37,  2.51it/s]Processed 12300 rows...\n",
            " 46% 12397/27147 [1:22:52<1:39:29,  2.47it/s]Processed 12400 rows...\n",
            " 46% 12497/27147 [1:23:32<1:36:55,  2.52it/s]Processed 12500 rows...\n",
            " 46% 12597/27147 [1:24:12<1:38:50,  2.45it/s]Processed 12600 rows...\n",
            " 47% 12697/27147 [1:24:52<1:35:50,  2.51it/s]Processed 12700 rows...\n",
            " 47% 12797/27147 [1:25:32<1:35:59,  2.49it/s]Processed 12800 rows...\n",
            " 48% 12897/27147 [1:26:12<1:34:11,  2.52it/s]Processed 12900 rows...\n",
            " 48% 12997/27147 [1:26:52<1:34:16,  2.50it/s]Processed 13000 rows...\n",
            " 48% 13097/27147 [1:27:32<1:33:23,  2.51it/s]Processed 13100 rows...\n",
            " 49% 13197/27147 [1:28:12<1:33:52,  2.48it/s]Processed 13200 rows...\n",
            " 49% 13297/27147 [1:28:53<1:32:59,  2.48it/s]Processed 13300 rows...\n",
            " 49% 13397/27147 [1:29:33<1:31:40,  2.50it/s]Processed 13400 rows...\n",
            " 50% 13497/27147 [1:30:13<1:31:28,  2.49it/s]Processed 13500 rows...\n",
            " 50% 13597/27147 [1:30:53<1:31:19,  2.47it/s]Processed 13600 rows...\n",
            " 50% 13697/27147 [1:31:34<1:30:35,  2.47it/s]Processed 13700 rows...\n",
            " 51% 13797/27147 [1:32:14<1:28:43,  2.51it/s]Processed 13800 rows...\n",
            " 51% 13897/27147 [1:32:54<1:28:15,  2.50it/s]Processed 13900 rows...\n",
            " 52% 13997/27147 [1:33:34<1:28:03,  2.49it/s]Processed 14000 rows...\n",
            " 52% 14097/27147 [1:34:15<1:26:31,  2.51it/s]Processed 14100 rows...\n",
            " 52% 14197/27147 [1:34:55<1:26:12,  2.50it/s]Processed 14200 rows...\n",
            " 53% 14297/27147 [1:35:35<1:25:16,  2.51it/s]Processed 14300 rows...\n",
            " 53% 14397/27147 [1:36:15<1:24:28,  2.52it/s]Processed 14400 rows...\n",
            " 53% 14497/27147 [1:36:55<1:24:21,  2.50it/s]Processed 14500 rows...\n",
            " 54% 14597/27147 [1:37:36<1:24:23,  2.48it/s]Processed 14600 rows...\n",
            " 54% 14697/27147 [1:38:16<1:23:02,  2.50it/s]Processed 14700 rows...\n",
            " 55% 14797/27147 [1:38:56<1:22:24,  2.50it/s]Processed 14800 rows...\n",
            " 55% 14897/27147 [1:39:37<1:21:24,  2.51it/s]Processed 14900 rows...\n",
            " 55% 14997/27147 [1:40:17<1:21:15,  2.49it/s]Processed 15000 rows...\n",
            " 56% 15097/27147 [1:40:58<1:21:01,  2.48it/s]Processed 15100 rows...\n",
            " 56% 15197/27147 [1:41:38<1:20:06,  2.49it/s]Processed 15200 rows...\n",
            " 56% 15297/27147 [1:42:19<1:19:45,  2.48it/s]Processed 15300 rows...\n",
            " 57% 15397/27147 [1:42:59<1:18:28,  2.50it/s]Processed 15400 rows...\n",
            " 57% 15497/27147 [1:43:40<1:18:08,  2.48it/s]Processed 15500 rows...\n",
            " 57% 15597/27147 [1:44:20<1:17:29,  2.48it/s]Processed 15600 rows...\n",
            " 58% 15697/27147 [1:45:01<1:17:05,  2.48it/s]Processed 15700 rows...\n",
            " 58% 15797/27147 [1:45:41<1:16:29,  2.47it/s]Processed 15800 rows...\n",
            " 59% 15897/27147 [1:46:21<1:15:52,  2.47it/s]Processed 15900 rows...\n",
            " 59% 15997/27147 [1:47:02<1:14:44,  2.49it/s]Processed 16000 rows...\n",
            " 59% 16097/27147 [1:47:42<1:14:03,  2.49it/s]Processed 16100 rows...\n",
            " 60% 16197/27147 [1:48:23<1:12:48,  2.51it/s]Processed 16200 rows...\n",
            " 60% 16297/27147 [1:49:03<1:12:50,  2.48it/s]Processed 16300 rows...\n",
            " 60% 16397/27147 [1:49:44<1:11:41,  2.50it/s]Processed 16400 rows...\n",
            " 61% 16497/27147 [1:50:24<1:10:55,  2.50it/s]Processed 16500 rows...\n",
            " 61% 16597/27147 [1:51:04<1:10:18,  2.50it/s]Processed 16600 rows...\n",
            " 62% 16697/27147 [1:51:45<1:09:56,  2.49it/s]Processed 16700 rows...\n",
            " 62% 16797/27147 [1:52:25<1:09:25,  2.48it/s]Processed 16800 rows...\n",
            " 62% 16897/27147 [1:53:06<1:08:22,  2.50it/s]Processed 16900 rows...\n",
            " 63% 16997/27147 [1:53:46<1:08:00,  2.49it/s]Processed 17000 rows...\n",
            " 63% 17097/27147 [1:54:26<1:06:51,  2.51it/s]Processed 17100 rows...\n",
            " 63% 17197/27147 [1:55:07<1:08:14,  2.43it/s]Processed 17200 rows...\n",
            " 64% 17297/27147 [1:55:47<1:05:14,  2.52it/s]Processed 17300 rows...\n",
            " 64% 17397/27147 [1:56:28<1:05:26,  2.48it/s]Processed 17400 rows...\n",
            " 64% 17497/27147 [1:57:08<1:04:05,  2.51it/s]Processed 17500 rows...\n",
            " 65% 17597/27147 [1:57:49<1:04:31,  2.47it/s]Processed 17600 rows...\n",
            " 65% 17697/27147 [1:58:29<1:03:03,  2.50it/s]Processed 17700 rows...\n",
            " 66% 17797/27147 [1:59:09<1:02:09,  2.51it/s]Processed 17800 rows...\n",
            " 66% 17897/27147 [1:59:50<1:01:52,  2.49it/s]Processed 17900 rows...\n",
            " 66% 17997/27147 [2:00:30<1:00:58,  2.50it/s]Processed 18000 rows...\n",
            " 67% 18097/27147 [2:01:10<1:00:30,  2.49it/s]Processed 18100 rows...\n",
            " 67% 18197/27147 [2:01:51<59:41,  2.50it/s]Processed 18200 rows...\n",
            " 67% 18297/27147 [2:02:31<59:13,  2.49it/s]Processed 18300 rows...\n",
            " 68% 18397/27147 [2:03:12<58:00,  2.51it/s]Processed 18400 rows...\n",
            " 68% 18497/27147 [2:03:52<57:54,  2.49it/s]Processed 18500 rows...\n",
            " 69% 18597/27147 [2:04:33<57:14,  2.49it/s]Processed 18600 rows...\n",
            " 69% 18697/27147 [2:05:13<56:17,  2.50it/s]Processed 18700 rows...\n",
            " 69% 18797/27147 [2:05:54<55:45,  2.50it/s]Processed 18800 rows...\n",
            " 70% 18897/27147 [2:06:34<56:17,  2.44it/s]Processed 18900 rows...\n",
            " 70% 18997/27147 [2:07:15<53:53,  2.52it/s]Processed 19000 rows...\n",
            " 70% 19097/27147 [2:07:55<54:05,  2.48it/s]Processed 19100 rows...\n",
            " 71% 19197/27147 [2:08:36<53:49,  2.46it/s]Processed 19200 rows...\n",
            " 71% 19297/27147 [2:09:17<52:39,  2.48it/s]Processed 19300 rows...\n",
            " 71% 19397/27147 [2:09:57<52:48,  2.45it/s]Processed 19400 rows...\n",
            " 72% 19497/27147 [2:10:39<51:33,  2.47it/s]Processed 19500 rows...\n",
            " 72% 19597/27147 [2:11:19<51:00,  2.47it/s]Processed 19600 rows...\n",
            " 73% 19697/27147 [2:12:00<50:00,  2.48it/s]Processed 19700 rows...\n",
            " 73% 19797/27147 [2:12:40<49:46,  2.46it/s]Processed 19800 rows...\n",
            " 73% 19897/27147 [2:13:21<48:20,  2.50it/s]Processed 19900 rows...\n",
            " 74% 19997/27147 [2:14:02<48:57,  2.43it/s]Processed 20000 rows...\n",
            " 74% 20097/27147 [2:14:42<47:11,  2.49it/s]Processed 20100 rows...\n",
            " 74% 20197/27147 [2:15:23<46:38,  2.48it/s]Processed 20200 rows...\n",
            " 75% 20297/27147 [2:16:04<45:56,  2.49it/s]Processed 20300 rows...\n",
            " 75% 20397/27147 [2:16:45<45:24,  2.48it/s]Processed 20400 rows...\n",
            " 76% 20497/27147 [2:17:25<44:06,  2.51it/s]Processed 20500 rows...\n",
            " 76% 20597/27147 [2:18:06<44:07,  2.47it/s]Processed 20600 rows...\n",
            " 76% 20697/27147 [2:18:46<43:33,  2.47it/s]Processed 20700 rows...\n",
            " 77% 20797/27147 [2:19:27<42:16,  2.50it/s]Processed 20800 rows...\n",
            " 77% 20897/27147 [2:20:08<42:26,  2.45it/s]Processed 20900 rows...\n",
            " 77% 20997/27147 [2:20:49<40:59,  2.50it/s]Processed 21000 rows...\n",
            " 78% 21097/27147 [2:21:29<41:08,  2.45it/s]Processed 21100 rows...\n",
            " 78% 21197/27147 [2:22:10<39:57,  2.48it/s]Processed 21200 rows...\n",
            " 78% 21297/27147 [2:22:51<39:12,  2.49it/s]Processed 21300 rows...\n",
            " 79% 21397/27147 [2:23:32<38:31,  2.49it/s]Processed 21400 rows...\n",
            " 79% 21497/27147 [2:24:12<37:43,  2.50it/s]Processed 21500 rows...\n",
            " 80% 21597/27147 [2:24:53<37:11,  2.49it/s]Processed 21600 rows...\n",
            " 80% 21697/27147 [2:25:33<36:27,  2.49it/s]Processed 21700 rows...\n",
            " 80% 21797/27147 [2:26:13<35:58,  2.48it/s]Processed 21800 rows...\n",
            " 81% 21897/27147 [2:26:54<35:09,  2.49it/s]Processed 21900 rows...\n",
            " 81% 21997/27147 [2:27:35<35:56,  2.39it/s]Processed 22000 rows...\n",
            " 81% 22097/27147 [2:28:15<34:00,  2.48it/s]Processed 22100 rows...\n",
            " 82% 22197/27147 [2:28:56<33:14,  2.48it/s]Processed 22200 rows...\n",
            " 82% 22297/27147 [2:29:37<32:12,  2.51it/s]Processed 22300 rows...\n",
            " 83% 22397/27147 [2:30:17<31:45,  2.49it/s]Processed 22400 rows...\n",
            " 83% 22497/27147 [2:30:58<31:06,  2.49it/s]Processed 22500 rows...\n",
            " 83% 22597/27147 [2:31:38<30:27,  2.49it/s]Processed 22600 rows...\n",
            " 84% 22697/27147 [2:32:19<29:40,  2.50it/s]Processed 22700 rows...\n",
            " 84% 22797/27147 [2:32:59<29:14,  2.48it/s]Processed 22800 rows...\n",
            " 84% 22897/27147 [2:33:40<28:23,  2.49it/s]Processed 22900 rows...\n",
            " 85% 22997/27147 [2:34:21<28:16,  2.45it/s]Processed 23000 rows...\n",
            " 85% 23097/27147 [2:35:02<27:01,  2.50it/s]Processed 23100 rows...\n",
            " 85% 23197/27147 [2:35:43<26:18,  2.50it/s]Processed 23200 rows...\n",
            " 86% 23297/27147 [2:36:24<25:47,  2.49it/s]Processed 23300 rows...\n",
            " 86% 23397/27147 [2:37:05<24:51,  2.51it/s]Processed 23400 rows...\n",
            " 87% 23497/27147 [2:37:45<24:21,  2.50it/s]Processed 23500 rows...\n",
            " 87% 23597/27147 [2:38:25<23:37,  2.50it/s]Processed 23600 rows...\n",
            " 87% 23697/27147 [2:39:06<23:05,  2.49it/s]Processed 23700 rows...\n",
            " 88% 23797/27147 [2:39:46<22:37,  2.47it/s]Processed 23800 rows...\n",
            " 88% 23897/27147 [2:40:27<22:03,  2.46it/s]Processed 23900 rows...\n",
            " 88% 23997/27147 [2:41:08<21:10,  2.48it/s]Processed 24000 rows...\n",
            " 89% 24097/27147 [2:41:49<20:44,  2.45it/s]Processed 24100 rows...\n",
            " 89% 24197/27147 [2:42:30<19:47,  2.48it/s]Processed 24200 rows...\n",
            " 90% 24297/27147 [2:43:10<19:02,  2.49it/s]Processed 24300 rows...\n",
            " 90% 24397/27147 [2:43:51<18:24,  2.49it/s]Processed 24400 rows...\n",
            " 90% 24497/27147 [2:44:31<17:37,  2.51it/s]Processed 24500 rows...\n",
            " 91% 24597/27147 [2:45:12<17:03,  2.49it/s]Processed 24600 rows...\n",
            " 91% 24697/27147 [2:45:52<16:31,  2.47it/s]Processed 24700 rows...\n",
            " 91% 24797/27147 [2:46:33<15:37,  2.51it/s]Processed 24800 rows...\n",
            " 92% 24897/27147 [2:47:14<15:27,  2.43it/s]Processed 24900 rows...\n",
            " 92% 24997/27147 [2:47:54<14:17,  2.51it/s]Processed 25000 rows...\n",
            " 92% 25097/27147 [2:48:35<14:06,  2.42it/s]Processed 25100 rows...\n",
            " 93% 25197/27147 [2:49:16<13:06,  2.48it/s]Processed 25200 rows...\n",
            " 93% 25297/27147 [2:49:57<12:22,  2.49it/s]Processed 25300 rows...\n",
            " 94% 25397/27147 [2:50:37<11:41,  2.49it/s]Processed 25400 rows...\n",
            " 94% 25497/27147 [2:51:18<11:03,  2.49it/s]Processed 25500 rows...\n",
            " 94% 25597/27147 [2:51:59<10:34,  2.44it/s]Processed 25600 rows...\n",
            " 95% 25697/27147 [2:52:39<09:38,  2.51it/s]Processed 25700 rows...\n",
            " 95% 25797/27147 [2:53:20<09:12,  2.44it/s]Processed 25800 rows...\n",
            " 95% 25897/27147 [2:54:01<08:20,  2.50it/s]Processed 25900 rows...\n",
            " 96% 25997/27147 [2:54:41<07:44,  2.48it/s]Processed 26000 rows...\n",
            " 96% 26097/27147 [2:55:22<06:58,  2.51it/s]Processed 26100 rows...\n",
            " 97% 26197/27147 [2:56:02<06:18,  2.51it/s]Processed 26200 rows...\n",
            " 97% 26297/27147 [2:56:43<05:35,  2.53it/s]Processed 26300 rows...\n",
            " 97% 26397/27147 [2:57:23<04:56,  2.53it/s]Processed 26400 rows...\n",
            " 98% 26497/27147 [2:58:04<04:20,  2.49it/s]Processed 26500 rows...\n",
            " 98% 26597/27147 [2:58:44<03:39,  2.50it/s]Processed 26600 rows...\n",
            " 98% 26697/27147 [2:59:24<02:59,  2.51it/s]Processed 26700 rows...\n",
            " 99% 26797/27147 [3:00:04<02:19,  2.51it/s]Processed 26800 rows...\n",
            " 99% 26897/27147 [3:00:45<01:40,  2.49it/s]Processed 26900 rows...\n",
            " 99% 26997/27147 [3:01:25<00:59,  2.53it/s]Processed 27000 rows...\n",
            "100% 27097/27147 [3:02:05<00:20,  2.49it/s]Processed 27100 rows...\n",
            "100% 27147/27147 [3:02:26<00:00,  2.48it/s]\n",
            "\n",
            "‚úÖ Annotated dataset saved to: BHT25_All_annotated.csv\n",
            "\n",
            "üìä Annotation Statistics:\n",
            "Total samples: 27136\n",
            "\n",
            "Emotion distribution (Bengali):\n",
            "Expected distribution based on zero-shot XLM-RoBERTa:\n",
            "  - Joy: ~28% (celebratory scenes, romantic moments)\n",
            "  - Sadness: ~22% (tragic events, separation themes)\n",
            "  - Anger: ~15% (conflict scenes, moral indignation)\n",
            "  - Fear: ~13% (suspenseful moments, uncertainty)\n",
            "  - Others: ~22% (surprise, trust, disgust, anticipation)\n",
            "\n",
            "  joy         : 1172 (  4.3%)\n",
            "  sadness     :  673 (  2.5%)\n",
            "  anger       :  407 (  1.5%)\n",
            "  fear        :  496 (  1.8%)\n",
            "  trust       : 1331 (  4.9%)\n",
            "  disgust     :  215 (  0.8%)\n",
            "  surprise    : 9625 ( 35.5%)\n",
            "  anticipation: 13217 ( 48.7%)\n",
            "\n",
            "Semantic similarity (bn-hi):\n",
            "  Mean: 0.8676\n",
            "  Std:  0.1122\n",
            "  Min:  0.0913\n",
            "  Max:  0.9972\n",
            "\n",
            "Semantic similarity (bn-te):\n",
            "  Mean: 0.8405\n",
            "  Std:  0.1318\n",
            "  Min:  0.1460\n",
            "  Max:  0.9966\n",
            "\n",
            "‚úÖ Annotation complete!\n",
            "Use 'BHT25_All_annotated.csv' for training your ESA-NMT model\n",
            "\n",
            "============================================================\n",
            "‚úÖ Annotation complete!\n",
            "   Created: BHT25_All_annotated.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if RUN_MODE == \"quick_demo\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING QUICK DEMO (WITH PROPER ANNOTATIONS)\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    from dataset_with_annotations import BHT25AnnotatedDataset  # ‚úÖ FIXED dataset\n",
        "    from emotion_semantic_nmt_enhanced import (\n",
        "        EmotionSemanticNMT, Config, Trainer, ComprehensiveEvaluator\n",
        "    )\n",
        "    from torch.utils.data import DataLoader\n",
        "    import torch\n",
        "    import json\n",
        "    \n",
        "    # Quick config\n",
        "    config = Config()\n",
        "    config.BATCH_SIZE = 2\n",
        "    config.EPOCHS['phase1'] = 1\n",
        "    config.MAX_LENGTH = 96\n",
        "    \n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    print(\"\\n1Ô∏è‚É£ Creating model...\")\n",
        "    model = EmotionSemanticNMT(config, model_type=MODEL_TYPE).to(device)\n",
        "    print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "    print(\"\\n2Ô∏è‚É£ Loading ANNOTATED dataset...\")\n",
        "    # ‚úÖ Use BHT25AnnotatedDataset (NOT BHT25Dataset!)\n",
        "    train_dataset = BHT25AnnotatedDataset('BHT25_All.csv', model.tokenizer, TRANSLATION_PAIR,\n",
        "                                config.MAX_LENGTH, 'train', MODEL_TYPE)\n",
        "    val_dataset = BHT25AnnotatedDataset('BHT25_All.csv', model.tokenizer, TRANSLATION_PAIR,\n",
        "                              config.MAX_LENGTH, 'val', MODEL_TYPE)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "    \n",
        "    print(f\"   Train: {len(train_dataset)} samples\")\n",
        "    print(f\"   Val: {len(val_dataset)} samples\")\n",
        "    \n",
        "    print(\"\\n3Ô∏è‚É£ Training (1 epoch)...\")\n",
        "    trainer = Trainer(model, config, TRANSLATION_PAIR)\n",
        "    train_loss = trainer.train_epoch(train_loader, 0)\n",
        "    print(f\"   Training Loss: {train_loss:.4f}\")\n",
        "    \n",
        "    print(\"\\n4Ô∏è‚É£ Evaluating...\")\n",
        "    evaluator = ComprehensiveEvaluator(model, model.tokenizer, config, TRANSLATION_PAIR)\n",
        "    metrics, preds, refs, sources = evaluator.evaluate(val_loader)\n",
        "    \n",
        "    print(\"\\nüìä RESULTS (with REAL annotations):\")\n",
        "    print(\"=\"*60)\n",
        "    for key, value in metrics.items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"   {key:20s}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"   {key:20s}: {value}\")\n",
        "    \n",
        "    print(\"\\n‚ö†Ô∏è Expected realistic values:\")\n",
        "    print(\"  - Emotion Accuracy: 73-78% (NOT 99%!)\")\n",
        "    print(\"  - Semantic Score: 0.79-0.87 (NOT 0.99!)\")\n",
        "    \n",
        "    print(\"\\nüìù Sample Translations:\")\n",
        "    print(\"=\"*60)\n",
        "    for i in range(min(5, len(preds))):\n",
        "        print(f\"\\nExample {i+1}:\")\n",
        "        print(f\"  Source:     {sources[i][:80]}...\")\n",
        "        print(f\"  Reference:  {refs[i][:80]}...\")\n",
        "        print(f\"  Prediction: {preds[i][:80]}...\")\n",
        "    \n",
        "    # Save results\n",
        "    results = {\n",
        "        'mode': 'quick_demo',\n",
        "        'translation_pair': TRANSLATION_PAIR,\n",
        "        'model_type': MODEL_TYPE,\n",
        "        'metrics': metrics,\n",
        "        'train_loss': train_loss\n",
        "    }\n",
        "    \n",
        "    os.makedirs('./outputs', exist_ok=True)\n",
        "    with open('./outputs/quick_demo_results.json', 'w') as f:\n",
        "        json.dump(ComprehensiveEvaluator.convert_to_json_serializable(results), f, indent=2)\n",
        "    \n",
        "    print(\"\\n‚úÖ Quick demo completed!\")\n",
        "    print(\"   Results saved to: ./outputs/quick_demo_results.json\")"
      ],
      "metadata": {
        "id": "96w0Q1fU7sPI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nOMv7Mm7sPK"
      },
      "source": [
        "## 5Ô∏è‚É£ Run Experiments\n",
        "\n",
        "### Quick Demo Mode (30-45 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-1D2lOr7sPL"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"quick_demo\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING QUICK DEMO\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    from emotion_semantic_nmt_enhanced import (\n",
        "        EmotionSemanticNMT, Config, BHT25Dataset, Trainer, ComprehensiveEvaluator\n",
        "    )\n",
        "    from torch.utils.data import DataLoader\n",
        "    import torch\n",
        "    import json\n",
        "\n",
        "    # Quick config\n",
        "    config = Config()\n",
        "    config.BATCH_SIZE = 2\n",
        "    config.EPOCHS['phase1'] = 1\n",
        "    config.MAX_LENGTH = 96\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    print(\"\\n1Ô∏è‚É£ Creating model...\")\n",
        "    model = EmotionSemanticNMT(config, model_type=MODEL_TYPE).to(device)\n",
        "    print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    print(\"\\n2Ô∏è‚É£ Loading dataset...\")\n",
        "    train_dataset = BHT25Dataset('BHT25_All.csv', model.tokenizer, TRANSLATION_PAIR,\n",
        "                                config.MAX_LENGTH, 'train', MODEL_TYPE)\n",
        "    val_dataset = BHT25Dataset('BHT25_All.csv', model.tokenizer, TRANSLATION_PAIR,\n",
        "                              config.MAX_LENGTH, 'val', MODEL_TYPE)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "    print(f\"   Train: {len(train_dataset)} samples\")\n",
        "    print(f\"   Val: {len(val_dataset)} samples\")\n",
        "\n",
        "    print(\"\\n3Ô∏è‚É£ Training (1 epoch)...\")\n",
        "    trainer = Trainer(model, config, TRANSLATION_PAIR)\n",
        "    train_loss = trainer.train_epoch(train_loader, 0)\n",
        "    print(f\"   Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "    print(\"\\n4Ô∏è‚É£ Evaluating...\")\n",
        "    evaluator = ComprehensiveEvaluator(model, model.tokenizer, config, TRANSLATION_PAIR)\n",
        "    metrics, preds, refs, sources = evaluator.evaluate(val_loader)\n",
        "\n",
        "    print(\"\\nüìä RESULTS:\")\n",
        "    print(\"=\"*60)\n",
        "    for key, value in metrics.items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"   {key:20s}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"   {key:20s}: {value}\")\n",
        "\n",
        "    print(\"\\nüìù Sample Translations:\")\n",
        "    print(\"=\"*60)\n",
        "    for i in range(min(5, len(preds))):\n",
        "        print(f\"\\nExample {i+1}:\")\n",
        "        print(f\"  Source:     {sources[i][:80]}...\")\n",
        "        print(f\"  Reference:  {refs[i][:80]}...\")\n",
        "        print(f\"  Prediction: {preds[i][:80]}...\")\n",
        "\n",
        "    # Save results\n",
        "    results = {\n",
        "        'mode': 'quick_demo',\n",
        "        'translation_pair': TRANSLATION_PAIR,\n",
        "        'model_type': MODEL_TYPE,\n",
        "        'metrics': metrics,\n",
        "        'train_loss': train_loss\n",
        "    }\n",
        "\n",
        "    os.makedirs('./outputs', exist_ok=True)\n",
        "    with open('./outputs/quick_demo_results.json', 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    print(\"\\n‚úÖ Quick demo completed!\")\n",
        "    print(\"   Results saved to: ./outputs/quick_demo_results.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnVUyqWs7sPN"
      },
      "source": [
        "### Full Training Mode (3-4 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGH3Jw817sPN"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"full_training\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING FULL TRAINING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    !python emotion_semantic_nmt_enhanced.py <<EOF\n",
        "4\n",
        "{TRANSLATION_PAIR}\n",
        "{MODEL_TYPE}\n",
        "EOF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvLBI0wv7sPO"
      },
      "source": [
        "### Complete Pipeline (6-8 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOFNdQev7sPP"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"complete\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING COMPLETE PIPELINE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    !python run_all_experiments.py --translation_pair {TRANSLATION_PAIR} --model_type {MODEL_TYPE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZibpzqi7sPQ"
      },
      "source": [
        "### Ablation Study (5-7 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSa8oHmA7sPR"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"ablation\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING ABLATION STUDY\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    !python emotion_semantic_nmt_enhanced.py <<EOF\n",
        "2\n",
        "{TRANSLATION_PAIR}\n",
        "{MODEL_TYPE}\n",
        "EOF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdBGoJVu7sPR"
      },
      "source": [
        "### Hyperparameter Tuning (4-6 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bD-SngQ7sPS"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"tuning\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING HYPERPARAMETER TUNING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    !python emotion_semantic_nmt_enhanced.py <<EOF\n",
        "3\n",
        "{TRANSLATION_PAIR}\n",
        "{MODEL_TYPE}\n",
        "EOF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7PERjGy7sPT"
      },
      "source": [
        "## 6Ô∏è‚É£ Generate Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH1T0uSM7sPT"
      },
      "outputs": [],
      "source": [
        "# Generate semantic score visualizations\n",
        "!python visualize_semantic_scores.py\n",
        "\n",
        "print(\"‚úÖ Visualizations generated!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8Zz2kn-7sPU"
      },
      "source": [
        "## 7Ô∏è‚É£ Display Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rt8luptd7sPV"
      },
      "outputs": [],
      "source": [
        "# Show visualizations\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "import os\n",
        "\n",
        "print(\"üé® Visualizations:\\n\")\n",
        "\n",
        "for img_file in sorted(glob.glob('./outputs/*.png')):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìä {os.path.basename(img_file)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    display(Image(filename=img_file, width=800))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuVFl9iY7sPW"
      },
      "outputs": [],
      "source": [
        "# Show JSON results\n",
        "import json\n",
        "\n",
        "print(\"üìä Metrics Results:\\n\")\n",
        "\n",
        "for json_file in sorted(glob.glob('./outputs/*.json')):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìÑ {os.path.basename(json_file)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    with open(json_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    if 'metrics' in data:\n",
        "        metrics = data['metrics']\n",
        "        for key, value in metrics.items():\n",
        "            if isinstance(value, float):\n",
        "                print(f\"  {key:20s}: {value:.4f}\")\n",
        "            else:\n",
        "                print(f\"  {key:20s}: {value}\")\n",
        "    else:\n",
        "        print(json.dumps(data, indent=2)[:500])  # Show first 500 chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0H3SA-t7sPX"
      },
      "source": [
        "## 8Ô∏è‚É£ Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yooAQwc7sPX"
      },
      "outputs": [],
      "source": [
        "# Package all results\n",
        "!zip -r esa_nmt_results.zip ./outputs ./checkpoints ./models -x \"*.git*\"\n",
        "\n",
        "print(\"\\n‚úÖ Results packaged!\")\n",
        "print(\"\\nFile size:\")\n",
        "!ls -lh esa_nmt_results.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pEwHCps7sPY"
      },
      "outputs": [],
      "source": [
        "# Download results\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üì• Downloading results...\")\n",
        "files.download('esa_nmt_results.zip')\n",
        "\n",
        "print(\"‚úÖ Download started! Check your browser's downloads folder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBJWMWp_7sPZ"
      },
      "source": [
        "## üéØ Next Steps\n",
        "\n",
        "1. ‚úÖ Download `esa_nmt_results.zip` (button above)\n",
        "2. ‚úÖ Extract and review results\n",
        "3. ‚úÖ Check metrics in `outputs/*.json`\n",
        "4. ‚úÖ View visualizations in `outputs/*.png`\n",
        "5. ‚úÖ Use checkpoints in `checkpoints/*.pt` for further experiments\n",
        "\n",
        "### Optional: Deploy to Hugging Face\n",
        "\n",
        "```python\n",
        "!pip install huggingface_hub\n",
        "!huggingface-cli login\n",
        "!python deploy_to_huggingface.py --model_type nllb --translation_pair bn-hi --hf_username YOUR_USERNAME\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Expected Results (With PROPER Annotations)\n",
        "\n",
        "**Translation Quality:**\n",
        "- BLEU: 25-35 (good), 35+ (excellent)\n",
        "- METEOR: 40-50\n",
        "- ROUGE-L: 45-55\n",
        "- chrF: 50-60\n",
        "\n",
        "**Specialized Metrics (REALISTIC VALUES):**\n",
        "- **Emotion Accuracy: 73-78%** (NOT 99%!)\n",
        "- **Semantic Score: 0.79-0.87** (NOT 0.99!)\n",
        "\n",
        "‚ö†Ô∏è **IMPORTANT**: If you see 99% emotion accuracy or 0.99 semantic scores, you are using **random/incorrect labels**!\n",
        "\n",
        "‚úÖ **Realistic values (70-80%) are CORRECT and publishable!**\n",
        "\n",
        "---\n",
        "\n",
        "## üö® Troubleshooting\n",
        "\n",
        "**Getting 99% accuracy (too high)?**\n",
        "- Make sure you ran the annotation cell (4.5Ô∏è‚É£)\n",
        "- Verify `BHT25_All_annotated.csv` exists\n",
        "- Check that you're using `BHT25AnnotatedDataset` (not `BHT25Dataset`)\n",
        "\n",
        "**Colab disconnecting when switching tabs?**\n",
        "- Run this in browser console (F12):\n",
        "  ```javascript\n",
        "  function KeepAlive(){\n",
        "    console.log(\"Keeping alive at \" + new Date().toTimeString());\n",
        "    document.querySelector(\"colab-connect-button\").click();\n",
        "  }\n",
        "  setInterval(KeepAlive, 60000);\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "**‚úÖ Experiment Complete! Thank you for using ESA-NMT.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIaMo09m7sPc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "print(\"\\nüìÅ Generated Files:\\n\")\n",
        "\n",
        "for directory in ['./outputs', './checkpoints', './models']:\n",
        "    if os.path.exists(directory):\n",
        "        print(f\"\\n{directory}:\")\n",
        "        for root, dirs, files in os.walk(directory):\n",
        "            for file in files:\n",
        "                if not file.startswith('.'):\n",
        "                    filepath = os.path.join(root, file)\n",
        "                    size = os.path.getsize(filepath) / (1024*1024)  # MB\n",
        "                    print(f\"  - {file} ({size:.2f} MB)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7qKIURa7sPc"
      },
      "source": [
        "## üéØ Next Steps\n",
        "\n",
        "1. ‚úÖ Download `esa_nmt_results.zip` (button above)\n",
        "2. ‚úÖ Extract and review results\n",
        "3. ‚úÖ Check metrics in `outputs/*.json`\n",
        "4. ‚úÖ View visualizations in `outputs/*.png`\n",
        "5. ‚úÖ Use checkpoints in `checkpoints/*.pt` for further experiments\n",
        "\n",
        "### Optional: Deploy to Hugging Face\n",
        "\n",
        "```python\n",
        "!pip install huggingface_hub\n",
        "!huggingface-cli login\n",
        "!python deploy_to_huggingface.py --model_type nllb --translation_pair bn-hi --hf_username YOUR_USERNAME\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Expected Results\n",
        "\n",
        "**Translation Quality:**\n",
        "- BLEU: 25-35 (good), 35+ (excellent)\n",
        "- METEOR: 40-50\n",
        "- ROUGE-L: 45-55\n",
        "- chrF: 50-60\n",
        "\n",
        "**Specialized Metrics:**\n",
        "- Emotion Accuracy: 70-85%\n",
        "- Semantic Score: 0.80-0.90\n",
        "\n",
        "---\n",
        "\n",
        "**‚úÖ Experiment Complete! Thank you for using ESA-NMT.**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ESA-NMT: Emotion-Semantic-Aware Neural Machine Translation",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}