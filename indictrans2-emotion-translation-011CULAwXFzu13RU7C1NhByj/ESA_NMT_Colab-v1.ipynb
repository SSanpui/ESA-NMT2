{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj1GFA0E3zh6"
      },
      "source": [
        "# ESA-NMT: Emotion-Semantic-Aware Neural Machine Translation\n",
        "\n",
        "**Bengali-Hindi-Telugu Translation with Emotion and Semantic Awareness**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SSanpui/ESA-NMT/blob/claude/indictrans2-emotion-translation-011CULAwXFzu13RU7C1NhByj/ESA_NMT_Colab.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Before You Start\n",
        "\n",
        "**Required:**\n",
        "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí **GPU**\n",
        "2. **Choose GPU**: T4 (free), V100/A100 (Pro)\n",
        "\n",
        "**Estimated Runtime:**\n",
        "- Quick Demo: 30-45 minutes (T4) / 15-20 minutes (V100)\n",
        "- Full Training: 3-4 hours (T4) / 1.5-2 hours (V100)\n",
        "- Complete Pipeline: 6-8 hours (T4) / 3-4 hours (V100)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6ERO2mH3zh-"
      },
      "source": [
        "## üîß Configuration\n",
        "\n",
        "**Choose what to run:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WFnSuWY03zh_",
        "outputId": "13dc8d5b-6c56-41e2-c7bb-d2464c108223",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Configuration:\n",
            "  - Mode: quick_demo\n",
            "  - Translation Pair: bn-hi\n",
            "  - Model Type: nllb\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ===== CONFIGURATION =====\n",
        "# Change these settings based on what you want to run\n",
        "\n",
        "RUN_MODE = \"quick_demo\"  # Options: \"quick_demo\", \"full_training\", \"ablation\", \"tuning\", \"complete\"\n",
        "TRANSLATION_PAIR = \"bn-hi\"  # Options: \"bn-hi\", \"bn-te\"\n",
        "MODEL_TYPE = \"nllb\"  # Options: \"nllb\", \"indictrans2\"\n",
        "\n",
        "print(f\"\"\"\\n{'='*60}\n",
        "Configuration:\n",
        "  - Mode: {RUN_MODE}\n",
        "  - Translation Pair: {TRANSLATION_PAIR}\n",
        "  - Model Type: {MODEL_TYPE}\n",
        "{'='*60}\\n\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2nEvwAH3ziB"
      },
      "source": [
        "## 1Ô∏è‚É£ Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RVnpvoDu3ziC",
        "outputId": "f0bba288-6a7a-4cb2-9292-3a55b7d7a440",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GPU Available: NVIDIA A100-SXM4-40GB\n",
            "‚úÖ GPU Memory: 39.6 GB\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WARNING: No GPU detected!\")\n",
        "    print(\"   Go to: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDLzo9oX3ziC"
      },
      "source": [
        "## 2Ô∏è‚É£ Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uBVqz8Ng3ziD",
        "outputId": "68af7482-588d-4080-dc1e-9f1b64be6de6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ESA-NMT'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 96 (delta 32), reused 53 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (96/96), 3.72 MiB | 3.25 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n",
            "/content/ESA-NMT\n",
            "Branch 'claude/indictrans2-emotion-translation-011CULAwXFzu13RU7C1NhByj' set up to track remote branch 'claude/indictrans2-emotion-translation-011CULAwXFzu13RU7C1NhByj' from 'origin'.\n",
            "Switched to a new branch 'claude/indictrans2-emotion-translation-011CULAwXFzu13RU7C1NhByj'\n",
            "‚úÖ Repository cloned and ready!\n"
          ]
        }
      ],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/SSanpui/ESA-NMT.git\n",
        "%cd ESA-NMT\n",
        "!git checkout claude/indictrans2-emotion-translation-011CULAwXFzu13RU7C1NhByj\n",
        "\n",
        "print(\"‚úÖ Repository cloned and ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQEeOMqf3ziD"
      },
      "source": [
        "## 3Ô∏è‚É£ Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eAm2-ydG3ziE",
        "outputId": "2b712c25-89f4-43cb-b4e0-4ba17a2a4276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers>=4.30.0 sentence-transformers>=2.2.0 sacrebleu>=2.3.0 \\\n",
        "    rouge-score>=0.1.2 accelerate>=0.20.0 datasets>=2.12.0\n",
        "\n",
        "# Install NLTK data\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "print(\"‚úÖ All dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix for JSON Serialization Error\n",
        "# Add this helper function to your notebook\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "def convert_to_serializable(obj):\n",
        "    \"\"\"Convert numpy types to Python types for JSON serialization\"\"\"\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif isinstance(obj, dict):\n",
        "        return {key: convert_to_serializable(value) for key, value in obj.items()}\n",
        "    elif isinstance(obj, list):\n",
        "        return [convert_to_serializable(item) for item in obj]\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "# Then when saving results, replace:\n",
        "# json.dump(results, f, indent=2)\n",
        "\n",
        "# With:\n",
        "json.dump(convert_to_serializable(results), f, indent=2)\n",
        "\n",
        "# OR use this simpler one-liner:\n",
        "# json.dump(results, f, indent=2, default=float)  # Converts all numeric types to float"
      ],
      "metadata": {
        "id": "sok-KdUF4V-7",
        "outputId": "5b3c3944-6a8c-4d7d-82c0-fca686e4f06a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'results' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1829543403.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# With:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_to_serializable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# OR use this simpler one-liner:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbRua2Im3ziF"
      },
      "source": [
        "## 4Ô∏è‚É£ Verify Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo4VGmHx3ziF"
      },
      "source": [
        "## üî• 4.5Ô∏è‚É£ Annotate Dataset with Multilingual Emotion Model (30-60 mins)\n",
        "\n",
        "**‚ö†Ô∏è IMPORTANT: Uses MilaNLProc/xlm-emo-t for literary content!**\n",
        "\n",
        "This annotation step:\n",
        "- Uses **MilaNLProc/xlm-emo-t** - multilingual emotion model (40+ languages)\n",
        "- Supports Bengali, Hindi, and Telugu text (Indic scripts)\n",
        "- **Suitable for traditional literary content** (not social media/news)\n",
        "- Classifies into 8 emotions: joy, sadness, anger, fear, trust, disgust, surprise, anticipation\n",
        "- Uses LaBSE for semantic similarity (cross-lingual sentence embeddings)\n",
        "\n",
        "**Expected emotion distribution for literary content:**\n",
        "- 20-30% joy (romantic moments, celebrations)\n",
        "- 20-25% sadness (tragic events, separation)\n",
        "- 10-15% anger (conflict, moral indignation)\n",
        "- 10-15% fear (suspense, uncertainty)\n",
        "- 10-15% trust (relationships, bonds)\n",
        "- 5-10% disgust (betrayal, dishonor)\n",
        "- 5-10% surprise (plot twists)\n",
        "- 5-10% anticipation (expectations)\n",
        "\n",
        "**‚ö†Ô∏è WARNING:** If you see 80%+ in just 1-2 emotions, the model is not working correctly!\n",
        "\n",
        "**Skip this cell if `BHT25_All_annotated.csv` already exists!**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üî• 4.5Ô∏è‚É£ Annotate Dataset with XLM-RoBERTa (ONE-TIME, 30-60 mins)\n",
        "\n",
        "**‚ö†Ô∏è IMPORTANT: Uses XLM-RoBERTa for cross-lingual emotion detection!**\n",
        "\n",
        "This annotation step:\n",
        "- Uses **XLM-RoBERTa-base** for zero-shot cross-lingual emotion classification\n",
        "- Supports Bengali, Hindi, and Telugu text (Indic scripts)\n",
        "- Classifies into 8 emotions: joy, sadness, anger, fear, trust, disgust, surprise, anticipation\n",
        "- Uses LaBSE for semantic similarity (cross-lingual sentence embeddings)\n",
        "\n",
        "**Expected emotion distribution:**\n",
        "- 28% joy (celebratory scenes, romantic moments)\n",
        "- 22% sadness (tragic events, separation)\n",
        "- 15% anger (conflict scenes)\n",
        "- 13% fear (suspenseful moments)\n",
        "- 22% others (surprise, trust, disgust, anticipation)\n",
        "\n",
        "**Skip this cell if `BHT25_All_annotated.csv` already exists!**"
      ],
      "metadata": {
        "id": "wb4jF2dx3ziF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if already annotated\n",
        "if os.path.exists('BHT25_All_annotated.csv'):\n",
        "    print(\"‚úÖ Annotated dataset already exists!\")\n",
        "    print(\"   Skipping annotation step...\")\n",
        "\n",
        "    # Show annotation stats\n",
        "    df_annotated = pd.read_csv('BHT25_All_annotated.csv')\n",
        "    print(f\"\\nüìä Annotation Statistics:\")\n",
        "    print(f\"   Total samples: {len(df_annotated)}\")\n",
        "    print(f\"   Columns: {df_annotated.columns.tolist()}\")\n",
        "\n",
        "    # Emotion distribution\n",
        "    if 'emotion_bn' in df_annotated.columns:\n",
        "        emotion_names = ['joy', 'sadness', 'anger', 'fear', 'trust', 'disgust', 'surprise', 'anticipation']\n",
        "        print(f\"\\n   Emotion distribution (Bengali):\")\n",
        "        for i in range(8):\n",
        "            count = (df_annotated['emotion_bn'] == i).sum()\n",
        "            pct = count / len(df_annotated) * 100\n",
        "            print(f\"     {emotion_names[i]:12s}: {count:4d} ({pct:5.1f}%)\")\n",
        "\n",
        "    # Semantic scores\n",
        "    if 'semantic_bn_hi' in df_annotated.columns:\n",
        "        print(f\"\\n   Semantic similarity (bn-hi):\")\n",
        "        print(f\"     Mean: {df_annotated['semantic_bn_hi'].mean():.4f}\")\n",
        "        print(f\"     Std:  {df_annotated['semantic_bn_hi'].std():.4f}\")\n",
        "\n",
        "else:\n",
        "    print(\"üîÑ Annotating dataset... (this will take 30-60 minutes)\")\n",
        "    print(\"‚è∞ Grab a coffee! This creates REAL emotion/semantic labels.\")\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Run annotation script\n",
        "    !python annotate_dataset.py\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ Annotation complete!\")\n",
        "    print(\"   Created: BHT25_All_annotated.csv\")"
      ],
      "metadata": {
        "id": "1el_FqUJ3ziF",
        "outputId": "464c5071-4749-40cc-dc1e-60bda288760f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Annotating dataset... (this will take 30-60 minutes)\n",
            "‚è∞ Grab a coffee! This creates REAL emotion/semantic labels.\n",
            "\n",
            "============================================================\n",
            "2025-10-27 04:15:00.275920: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-10-27 04:15:00.292737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761538500.314328    2107 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761538500.320736    2107 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761538500.336832    2107 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761538500.336861    2107 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761538500.336864    2107 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761538500.336867    2107 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-27 04:15:00.341696: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "üîÑ Loading annotation models...\n",
            "   Using multilingual emotion model for literary content...\n",
            "config.json: 1.01kB [00:00, 1.51MB/s]\n",
            "pytorch_model.bin: 100% 1.11G/1.11G [00:10<00:00, 106MB/s]\n",
            "sentencepiece.bpe.model:   0% 0.00/5.07M [00:00<?, ?B/s]\n",
            "model.safetensors:   0% 0.00/1.11G [00:00<?, ?B/s]\u001b[A\n",
            "sentencepiece.bpe.model:   4% 198k/5.07M [00:01<00:38, 126kB/s]\n",
            "model.safetensors:  42% 470M/1.11G [00:01<00:01, 437MB/s]\u001b[A\n",
            "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:02<00:00, 1.90MB/s]\n",
            "tokenizer.json: 9.10MB [00:00, 16.8MB/s]\n",
            "Device set to use cuda:0\n",
            "modules.json: 100% 461/461 [00:00<00:00, 2.18MB/s]\n",
            "\n",
            "model.safetensors:  82% 911M/1.11G [00:06<00:01, 108MB/s]\u001b[A\n",
            "model.safetensors: 100% 1.11G/1.11G [00:06<00:00, 166MB/s]\n",
            "config_sentence_transformers.json: 100% 122/122 [00:00<00:00, 884kB/s]\n",
            "README.md: 2.02kB [00:00, 10.7MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 413kB/s]\n",
            "config.json: 100% 804/804 [00:00<00:00, 5.03MB/s]\n",
            "model.safetensors: 100% 1.88G/1.88G [00:11<00:00, 163MB/s]\n",
            "tokenizer_config.json: 100% 397/397 [00:00<00:00, 2.66MB/s]\n",
            "vocab.txt: 5.22MB [00:00, 111MB/s]\n",
            "tokenizer.json: 9.62MB [00:00, 130MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 665kB/s]\n",
            "config.json: 100% 190/190 [00:00<00:00, 1.28MB/s]\n",
            "config.json: 100% 114/114 [00:00<00:00, 1.47MB/s]\n",
            "2_Dense/model.safetensors: 100% 2.36M/2.36M [00:00<00:00, 4.16MB/s]\n",
            "‚úÖ Models loaded!\n",
            "\n",
            "üìÇ Loading dataset from: BHT25_All.csv\n",
            "Dataset shape: (27149, 3)\n",
            "Columns: ['bn', 'hi', 'te']\n",
            "After removing NaN: (27147, 3)\n",
            "\n",
            "üîÑ Annotating dataset (this may take a while)...\n",
            "  0% 3/27147 [00:01<2:10:43,  3.46it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  0% 99/27147 [00:07<27:51, 16.18it/s]Processed 100 rows...\n",
            "  1% 199/27147 [00:13<27:20, 16.43it/s]Processed 200 rows...\n",
            "  1% 299/27147 [00:19<26:53, 16.64it/s]Processed 300 rows...\n",
            "  1% 398/27147 [00:25<28:04, 15.88it/s]Processed 400 rows...\n",
            "  2% 498/27147 [00:31<27:16, 16.28it/s]Processed 500 rows...\n",
            "  2% 598/27147 [00:37<27:22, 16.16it/s]Processed 600 rows...\n",
            "  3% 698/27147 [00:43<27:18, 16.14it/s]Processed 700 rows...\n",
            "  3% 798/27147 [00:49<27:11, 16.15it/s]Processed 800 rows...\n",
            "  3% 898/27147 [00:55<26:35, 16.45it/s]Processed 900 rows...\n",
            "  4% 999/27147 [01:02<27:18, 15.96it/s]Processed 1000 rows...\n",
            "  4% 1098/27147 [01:07<25:58, 16.71it/s]Processed 1100 rows...\n",
            "  4% 1199/27147 [01:13<26:44, 16.17it/s]Processed 1200 rows...\n",
            "  5% 1299/27147 [01:20<25:58, 16.58it/s]Processed 1300 rows...\n",
            "  5% 1399/27147 [01:26<26:17, 16.32it/s]Processed 1400 rows...\n",
            "  6% 1499/27147 [01:32<25:55, 16.48it/s]Processed 1500 rows...\n",
            "  6% 1599/27147 [01:38<25:56, 16.42it/s]Processed 1600 rows...\n",
            "  6% 1699/27147 [01:44<25:28, 16.65it/s]Processed 1700 rows...\n",
            "  7% 1799/27147 [01:50<25:20, 16.67it/s]Processed 1800 rows...\n",
            "  7% 1898/27147 [01:56<25:03, 16.79it/s]Processed 1900 rows...\n",
            "  7% 1998/27147 [02:02<25:15, 16.59it/s]Processed 2000 rows...\n",
            "  8% 2099/27147 [02:08<21:50, 19.11it/s]Processed 2100 rows...\n",
            "  8% 2199/27147 [02:14<26:05, 15.94it/s]Processed 2200 rows...\n",
            "  8% 2299/27147 [02:21<25:41, 16.12it/s]Processed 2300 rows...\n",
            "  9% 2399/27147 [02:27<24:55, 16.54it/s]Processed 2400 rows...\n",
            "  9% 2498/27147 [02:33<25:18, 16.23it/s]Processed 2500 rows...\n",
            " 10% 2598/27147 [02:39<24:52, 16.45it/s]Processed 2600 rows...\n",
            " 10% 2698/27147 [02:45<25:06, 16.23it/s]Processed 2700 rows...\n",
            " 10% 2799/27147 [02:51<25:41, 15.80it/s]Processed 2800 rows...\n",
            " 11% 2899/27147 [02:57<23:55, 16.89it/s]Processed 2900 rows...\n",
            " 11% 2999/27147 [03:03<24:06, 16.70it/s]Processed 3000 rows...\n",
            " 11% 3099/27147 [03:09<23:55, 16.75it/s]Processed 3100 rows...\n",
            " 12% 3198/27147 [03:15<24:16, 16.44it/s]Processed 3200 rows...\n",
            " 12% 3298/27147 [03:21<24:10, 16.44it/s]Processed 3300 rows...\n",
            " 13% 3398/27147 [03:27<24:44, 15.99it/s]Processed 3400 rows...\n",
            " 13% 3498/27147 [03:33<23:31, 16.75it/s]Processed 3500 rows...\n",
            " 13% 3598/27147 [03:39<23:46, 16.50it/s]Processed 3600 rows...\n",
            " 14% 3698/27147 [03:46<23:29, 16.64it/s]Processed 3700 rows...\n",
            " 14% 3798/27147 [03:52<23:49, 16.33it/s]Processed 3800 rows...\n",
            " 14% 3898/27147 [03:58<23:30, 16.48it/s]Processed 3900 rows...\n",
            " 15% 3998/27147 [04:04<23:36, 16.34it/s]Processed 4000 rows...\n",
            " 15% 4098/27147 [04:10<22:56, 16.74it/s]Processed 4100 rows...\n",
            " 15% 4198/27147 [04:16<23:46, 16.09it/s]Processed 4200 rows...\n",
            " 16% 4298/27147 [04:23<23:31, 16.19it/s]Processed 4300 rows...\n",
            " 16% 4398/27147 [04:29<23:32, 16.10it/s]Processed 4400 rows...\n",
            " 17% 4498/27147 [04:35<22:47, 16.57it/s]Processed 4500 rows...\n",
            " 17% 4598/27147 [04:41<22:57, 16.37it/s]Processed 4600 rows...\n",
            " 17% 4698/27147 [04:47<22:05, 16.93it/s]Processed 4700 rows...\n",
            " 18% 4798/27147 [04:53<22:39, 16.44it/s]Processed 4800 rows...\n",
            " 18% 4898/27147 [05:00<22:24, 16.54it/s]Processed 4900 rows...\n",
            " 18% 4998/27147 [05:06<22:27, 16.43it/s]Processed 5000 rows...\n",
            " 19% 5098/27147 [05:12<22:30, 16.33it/s]Processed 5100 rows...\n",
            " 19% 5198/27147 [05:18<21:52, 16.73it/s]Processed 5200 rows...\n",
            " 20% 5298/27147 [05:24<22:25, 16.24it/s]Processed 5300 rows...\n",
            " 20% 5398/27147 [05:30<22:03, 16.43it/s]Processed 5400 rows...\n",
            " 20% 5498/27147 [05:37<22:36, 15.96it/s]Processed 5500 rows...\n",
            " 21% 5598/27147 [05:43<22:00, 16.32it/s]Processed 5600 rows...\n",
            " 21% 5698/27147 [05:49<21:06, 16.93it/s]Processed 5700 rows...\n",
            " 21% 5798/27147 [05:55<21:53, 16.26it/s]Processed 5800 rows...\n",
            " 22% 5898/27147 [06:01<21:34, 16.41it/s]Processed 5900 rows...\n",
            " 22% 5998/27147 [06:07<21:31, 16.37it/s]Processed 6000 rows...\n",
            " 22% 6098/27147 [06:14<21:03, 16.66it/s]Processed 6100 rows...\n",
            " 23% 6198/27147 [06:20<21:21, 16.35it/s]Processed 6200 rows...\n",
            " 23% 6298/27147 [06:26<20:58, 16.56it/s]Processed 6300 rows...\n",
            " 24% 6398/27147 [06:32<21:09, 16.35it/s]Processed 6400 rows...\n",
            " 24% 6498/27147 [06:38<20:51, 16.50it/s]Processed 6500 rows...\n",
            " 24% 6598/27147 [06:44<21:45, 15.74it/s]Processed 6600 rows...\n",
            " 25% 6698/27147 [06:51<20:57, 16.27it/s]Processed 6700 rows...\n",
            " 25% 6798/27147 [06:57<21:07, 16.05it/s]Processed 6800 rows...\n",
            " 25% 6898/27147 [07:03<20:47, 16.23it/s]Processed 6900 rows...\n",
            " 26% 6998/27147 [07:09<20:12, 16.62it/s]Processed 7000 rows...\n",
            " 26% 7098/27147 [07:15<19:50, 16.84it/s]Processed 7100 rows...\n",
            " 27% 7198/27147 [07:21<19:57, 16.65it/s]Processed 7200 rows...\n",
            " 27% 7298/27147 [07:28<19:54, 16.61it/s]Processed 7300 rows...\n",
            " 27% 7396/27147 [07:34<20:10, 16.31it/s]Processed 7400 rows...\n",
            " 28% 7496/27147 [07:40<20:12, 16.21it/s]Processed 7500 rows...\n",
            " 28% 7596/27147 [07:46<19:43, 16.52it/s]Processed 7600 rows...\n",
            " 28% 7696/27147 [07:52<19:15, 16.83it/s]Processed 7700 rows...\n",
            " 29% 7796/27147 [07:58<19:44, 16.34it/s]Processed 7800 rows...\n",
            " 29% 7896/27147 [08:05<19:34, 16.39it/s]Processed 7900 rows...\n",
            " 29% 7996/27147 [08:11<19:00, 16.80it/s]Processed 8000 rows...\n",
            " 30% 8096/27147 [08:17<19:23, 16.38it/s]Processed 8100 rows...\n",
            " 30% 8196/27147 [08:23<19:09, 16.49it/s]Processed 8200 rows...\n",
            " 31% 8296/27147 [08:29<19:00, 16.53it/s]Processed 8300 rows...\n",
            " 31% 8396/27147 [08:36<18:50, 16.59it/s]Processed 8400 rows...\n",
            " 31% 8496/27147 [08:42<18:38, 16.68it/s]Processed 8500 rows...\n",
            " 32% 8596/27147 [08:48<18:23, 16.81it/s]Processed 8600 rows...\n",
            " 32% 8696/27147 [08:54<18:29, 16.64it/s]Processed 8700 rows...\n",
            " 32% 8796/27147 [09:00<18:40, 16.38it/s]Processed 8800 rows...\n",
            " 33% 8896/27147 [09:07<18:13, 16.69it/s]Processed 8900 rows...\n",
            " 33% 8996/27147 [09:13<18:29, 16.37it/s]Processed 9000 rows...\n",
            " 34% 9096/27147 [09:19<18:20, 16.41it/s]Processed 9100 rows...\n",
            " 34% 9196/27147 [09:25<18:43, 15.98it/s]Processed 9200 rows...\n",
            " 34% 9296/27147 [09:32<17:43, 16.79it/s]Processed 9300 rows...\n",
            " 35% 9396/27147 [09:38<17:54, 16.53it/s]Processed 9400 rows...\n",
            " 35% 9496/27147 [09:44<17:23, 16.92it/s]Processed 9500 rows...\n",
            " 35% 9596/27147 [09:50<18:21, 15.93it/s]Processed 9600 rows...\n",
            " 36% 9696/27147 [09:57<17:43, 16.41it/s]Processed 9700 rows...\n",
            " 36% 9796/27147 [10:03<17:52, 16.17it/s]Processed 9800 rows...\n",
            " 36% 9896/27147 [10:09<17:19, 16.60it/s]Processed 9900 rows...\n",
            " 37% 9996/27147 [10:15<17:32, 16.29it/s]Processed 10000 rows...\n",
            " 37% 10096/27147 [10:22<17:26, 16.29it/s]Processed 10100 rows...\n",
            " 38% 10196/27147 [10:28<17:18, 16.32it/s]Processed 10200 rows...\n",
            " 38% 10296/27147 [10:34<17:05, 16.44it/s]Processed 10300 rows...\n",
            " 38% 10396/27147 [10:40<17:02, 16.38it/s]Processed 10400 rows...\n",
            " 39% 10496/27147 [10:47<16:54, 16.42it/s]Processed 10500 rows...\n",
            " 39% 10596/27147 [10:53<16:52, 16.35it/s]Processed 10600 rows...\n",
            " 39% 10696/27147 [10:59<16:16, 16.84it/s]Processed 10700 rows...\n",
            " 40% 10796/27147 [11:05<16:43, 16.30it/s]Processed 10800 rows...\n",
            " 40% 10896/27147 [11:12<16:36, 16.30it/s]Processed 10900 rows...\n",
            " 41% 10996/27147 [11:18<16:23, 16.41it/s]Processed 11000 rows...\n",
            " 41% 11096/27147 [11:24<16:03, 16.65it/s]Processed 11100 rows...\n",
            " 41% 11196/27147 [11:30<16:08, 16.47it/s]Processed 11200 rows...\n",
            " 42% 11296/27147 [11:37<15:55, 16.59it/s]Processed 11300 rows...\n",
            " 42% 11396/27147 [11:43<15:52, 16.54it/s]Processed 11400 rows...\n",
            " 42% 11496/27147 [11:49<15:39, 16.66it/s]Processed 11500 rows...\n",
            " 43% 11596/27147 [11:55<15:51, 16.35it/s]Processed 11600 rows...\n",
            " 43% 11696/27147 [12:02<16:01, 16.07it/s]Processed 11700 rows...\n",
            " 43% 11796/27147 [12:08<15:26, 16.57it/s]Processed 11800 rows...\n",
            " 44% 11896/27147 [12:14<15:14, 16.68it/s]Processed 11900 rows...\n",
            " 44% 11996/27147 [12:20<14:55, 16.92it/s]Processed 12000 rows...\n",
            " 45% 12096/27147 [12:27<15:23, 16.30it/s]Processed 12100 rows...\n",
            " 45% 12196/27147 [12:33<14:54, 16.71it/s]Processed 12200 rows...\n",
            " 45% 12296/27147 [12:39<15:06, 16.39it/s]Processed 12300 rows...\n",
            " 46% 12396/27147 [12:45<14:25, 17.04it/s]Processed 12400 rows...\n",
            " 46% 12496/27147 [12:52<14:29, 16.85it/s]Processed 12500 rows...\n",
            " 46% 12596/27147 [12:58<14:30, 16.72it/s]Processed 12600 rows...\n",
            " 47% 12696/27147 [13:04<14:52, 16.18it/s]Processed 12700 rows...\n",
            " 47% 12796/27147 [13:10<14:13, 16.82it/s]Processed 12800 rows...\n",
            " 48% 12896/27147 [13:16<14:02, 16.91it/s]Processed 12900 rows...\n",
            " 48% 12996/27147 [13:23<14:05, 16.74it/s]Processed 13000 rows...\n",
            " 48% 13096/27147 [13:29<14:04, 16.65it/s]Processed 13100 rows...\n",
            " 49% 13196/27147 [13:35<14:04, 16.52it/s]Processed 13200 rows...\n",
            " 49% 13296/27147 [13:41<13:51, 16.66it/s]Processed 13300 rows...\n",
            " 49% 13396/27147 [13:48<13:41, 16.73it/s]Processed 13400 rows...\n",
            " 50% 13496/27147 [13:54<13:34, 16.76it/s]Processed 13500 rows...\n",
            " 50% 13596/27147 [14:00<13:52, 16.28it/s]Processed 13600 rows...\n",
            " 50% 13696/27147 [14:06<13:33, 16.53it/s]Processed 13700 rows...\n",
            " 51% 13796/27147 [14:13<13:41, 16.25it/s]Processed 13800 rows...\n",
            " 51% 13896/27147 [14:19<13:12, 16.72it/s]Processed 13900 rows...\n",
            " 52% 13996/27147 [14:25<13:14, 16.56it/s]Processed 14000 rows...\n",
            " 52% 14096/27147 [14:31<13:03, 16.65it/s]Processed 14100 rows...\n",
            " 52% 14196/27147 [14:38<13:03, 16.52it/s]Processed 14200 rows...\n",
            " 53% 14296/27147 [14:44<12:55, 16.58it/s]Processed 14300 rows...\n",
            " 53% 14396/27147 [14:50<12:44, 16.69it/s]Processed 14400 rows...\n",
            " 53% 14496/27147 [14:56<12:34, 16.77it/s]Processed 14500 rows...\n",
            " 54% 14596/27147 [15:03<12:36, 16.60it/s]Processed 14600 rows...\n",
            " 54% 14696/27147 [15:09<12:38, 16.41it/s]Processed 14700 rows...\n",
            " 55% 14796/27147 [15:15<12:16, 16.77it/s]Processed 14800 rows...\n",
            " 55% 14896/27147 [15:21<12:11, 16.74it/s]Processed 14900 rows...\n",
            " 55% 14996/27147 [15:28<12:06, 16.72it/s]Processed 15000 rows...\n",
            " 56% 15096/27147 [15:34<12:15, 16.38it/s]Processed 15100 rows...\n",
            " 56% 15196/27147 [15:40<11:54, 16.73it/s]Processed 15200 rows...\n",
            " 56% 15296/27147 [15:47<11:59, 16.47it/s]Processed 15300 rows...\n",
            " 57% 15396/27147 [15:53<11:56, 16.40it/s]Processed 15400 rows...\n",
            " 57% 15496/27147 [15:59<11:35, 16.75it/s]Processed 15500 rows...\n",
            " 57% 15596/27147 [16:06<11:59, 16.05it/s]Processed 15600 rows...\n",
            " 58% 15696/27147 [16:12<11:29, 16.60it/s]Processed 15700 rows...\n",
            " 58% 15796/27147 [16:18<11:39, 16.24it/s]Processed 15800 rows...\n",
            " 59% 15896/27147 [16:24<11:40, 16.06it/s]Processed 15900 rows...\n",
            " 59% 15996/27147 [16:31<11:24, 16.30it/s]Processed 16000 rows...\n",
            " 59% 16096/27147 [16:37<11:22, 16.19it/s]Processed 16100 rows...\n",
            " 60% 16196/27147 [16:43<10:53, 16.76it/s]Processed 16200 rows...\n",
            " 60% 16296/27147 [16:50<10:55, 16.56it/s]Processed 16300 rows...\n",
            " 60% 16396/27147 [16:56<10:45, 16.64it/s]Processed 16400 rows...\n",
            " 61% 16496/27147 [17:02<10:37, 16.70it/s]Processed 16500 rows...\n",
            " 61% 16596/27147 [17:09<10:19, 17.02it/s]Processed 16600 rows...\n",
            " 62% 16696/27147 [17:15<10:39, 16.34it/s]Processed 16700 rows...\n",
            " 62% 16796/27147 [17:21<10:24, 16.58it/s]Processed 16800 rows...\n",
            " 62% 16896/27147 [17:28<10:32, 16.21it/s]Processed 16900 rows...\n",
            " 63% 16996/27147 [17:34<10:09, 16.64it/s]Processed 17000 rows...\n",
            " 63% 17096/27147 [17:40<09:56, 16.85it/s]Processed 17100 rows...\n",
            " 63% 17196/27147 [17:46<10:04, 16.45it/s]Processed 17200 rows...\n",
            " 64% 17296/27147 [17:53<09:46, 16.78it/s]Processed 17300 rows...\n",
            " 64% 17396/27147 [17:59<09:49, 16.54it/s]Processed 17400 rows...\n",
            " 64% 17496/27147 [18:05<09:41, 16.60it/s]Processed 17500 rows...\n",
            " 65% 17596/27147 [18:12<09:40, 16.44it/s]Processed 17600 rows...\n",
            " 65% 17696/27147 [18:18<09:20, 16.85it/s]Processed 17700 rows...\n",
            " 66% 17796/27147 [18:24<09:28, 16.45it/s]Processed 17800 rows...\n",
            " 66% 17896/27147 [18:31<09:27, 16.30it/s]Processed 17900 rows...\n",
            " 66% 17996/27147 [18:37<09:19, 16.35it/s]Processed 18000 rows...\n",
            " 67% 18096/27147 [18:43<09:06, 16.55it/s]Processed 18100 rows...\n",
            " 67% 18196/27147 [18:50<08:56, 16.69it/s]Processed 18200 rows...\n",
            " 67% 18296/27147 [18:56<08:52, 16.61it/s]Processed 18300 rows...\n",
            " 68% 18396/27147 [19:02<08:38, 16.88it/s]Processed 18400 rows...\n",
            " 68% 18496/27147 [19:09<09:10, 15.73it/s]Processed 18500 rows...\n",
            " 69% 18596/27147 [19:15<08:39, 16.46it/s]Processed 18600 rows...\n",
            " 69% 18696/27147 [19:21<08:34, 16.43it/s]Processed 18700 rows...\n",
            " 69% 18796/27147 [19:28<08:18, 16.77it/s]Processed 18800 rows...\n",
            " 70% 18896/27147 [19:34<08:22, 16.43it/s]Processed 18900 rows...\n",
            " 70% 18996/27147 [19:40<08:15, 16.44it/s]Processed 19000 rows...\n",
            " 70% 19096/27147 [19:47<08:04, 16.61it/s]Processed 19100 rows...\n",
            " 71% 19196/27147 [19:53<07:57, 16.64it/s]Processed 19200 rows...\n",
            " 71% 19296/27147 [20:00<08:08, 16.08it/s]Processed 19300 rows...\n",
            " 71% 19396/27147 [20:06<07:58, 16.22it/s]Processed 19400 rows...\n",
            " 72% 19496/27147 [20:13<08:00, 15.91it/s]Processed 19500 rows...\n",
            " 72% 19596/27147 [20:19<07:52, 15.97it/s]Processed 19600 rows...\n",
            " 73% 19696/27147 [20:26<07:44, 16.06it/s]Processed 19700 rows...\n",
            " 73% 19796/27147 [20:32<07:37, 16.06it/s]Processed 19800 rows...\n",
            " 73% 19896/27147 [20:39<07:31, 16.07it/s]Processed 19900 rows...\n",
            " 74% 19996/27147 [20:45<07:22, 16.15it/s]Processed 20000 rows...\n",
            " 74% 20096/27147 [20:52<07:14, 16.24it/s]Processed 20100 rows...\n",
            " 74% 20196/27147 [20:58<07:01, 16.50it/s]Processed 20200 rows...\n",
            " 75% 20296/27147 [21:05<07:07, 16.04it/s]Processed 20300 rows...\n",
            " 75% 20396/27147 [21:11<06:49, 16.50it/s]Processed 20400 rows...\n",
            " 76% 20496/27147 [21:17<06:47, 16.32it/s]Processed 20500 rows...\n",
            " 76% 20596/27147 [21:24<06:37, 16.48it/s]Processed 20600 rows...\n",
            " 76% 20696/27147 [21:30<06:28, 16.59it/s]Processed 20700 rows...\n",
            " 77% 20796/27147 [21:37<06:33, 16.14it/s]Processed 20800 rows...\n",
            " 77% 20896/27147 [21:43<06:17, 16.57it/s]Processed 20900 rows...\n",
            " 77% 20996/27147 [21:49<06:14, 16.43it/s]Processed 21000 rows...\n",
            " 78% 21096/27147 [21:56<06:07, 16.47it/s]Processed 21100 rows...\n",
            " 78% 21196/27147 [22:02<06:07, 16.17it/s]Processed 21200 rows...\n",
            " 78% 21296/27147 [22:09<05:55, 16.45it/s]Processed 21300 rows...\n",
            " 79% 21396/27147 [22:15<05:47, 16.54it/s]Processed 21400 rows...\n",
            " 79% 21496/27147 [22:21<05:45, 16.34it/s]Processed 21500 rows...\n",
            " 80% 21596/27147 [22:28<05:35, 16.54it/s]Processed 21600 rows...\n",
            " 80% 21696/27147 [22:34<05:34, 16.32it/s]Processed 21700 rows...\n",
            " 80% 21796/27147 [22:41<05:19, 16.74it/s]Processed 21800 rows...\n",
            " 81% 21896/27147 [22:47<05:21, 16.36it/s]Processed 21900 rows...\n",
            " 81% 21996/27147 [22:53<05:09, 16.65it/s]Processed 22000 rows...\n",
            " 81% 22096/27147 [23:00<05:06, 16.50it/s]Processed 22100 rows...\n",
            " 82% 22196/27147 [23:06<04:53, 16.87it/s]Processed 22200 rows...\n",
            " 82% 22296/27147 [23:13<04:53, 16.54it/s]Processed 22300 rows...\n",
            " 82% 22396/27147 [23:19<04:48, 16.46it/s]Processed 22400 rows...\n",
            " 83% 22496/27147 [23:25<04:38, 16.69it/s]Processed 22500 rows...\n",
            " 83% 22596/27147 [23:32<04:45, 15.96it/s]Processed 22600 rows...\n",
            " 84% 22696/27147 [23:38<04:26, 16.72it/s]Processed 22700 rows...\n",
            " 84% 22796/27147 [23:45<04:25, 16.41it/s]Processed 22800 rows...\n",
            " 84% 22896/27147 [23:51<04:15, 16.65it/s]Processed 22900 rows...\n",
            " 85% 22996/27147 [23:57<04:19, 16.02it/s]Processed 23000 rows...\n",
            " 85% 23096/27147 [24:04<04:03, 16.64it/s]Processed 23100 rows...\n",
            " 85% 23196/27147 [24:10<04:00, 16.45it/s]Processed 23200 rows...\n",
            " 86% 23296/27147 [24:17<03:51, 16.62it/s]Processed 23300 rows...\n",
            " 86% 23396/27147 [24:23<03:48, 16.40it/s]Processed 23400 rows...\n",
            " 87% 23496/27147 [24:29<03:37, 16.80it/s]Processed 23500 rows...\n",
            " 87% 23596/27147 [24:36<03:37, 16.32it/s]Processed 23600 rows...\n",
            " 87% 23696/27147 [24:42<03:29, 16.44it/s]Processed 23700 rows...\n",
            " 88% 23796/27147 [24:48<03:24, 16.37it/s]Processed 23800 rows...\n",
            " 88% 23896/27147 [24:55<03:23, 16.00it/s]Processed 23900 rows...\n",
            " 88% 23996/27147 [25:01<03:10, 16.50it/s]Processed 24000 rows...\n",
            " 89% 24096/27147 [25:08<03:05, 16.45it/s]Processed 24100 rows...\n",
            " 89% 24196/27147 [25:14<02:59, 16.47it/s]Processed 24200 rows...\n",
            " 89% 24296/27147 [25:20<02:50, 16.70it/s]Processed 24300 rows...\n",
            " 90% 24396/27147 [25:27<02:43, 16.86it/s]Processed 24400 rows...\n",
            " 90% 24496/27147 [25:33<02:41, 16.38it/s]Processed 24500 rows...\n",
            " 91% 24596/27147 [25:40<02:40, 15.94it/s]Processed 24600 rows...\n",
            " 91% 24696/27147 [25:46<02:26, 16.76it/s]Processed 24700 rows...\n",
            " 91% 24796/27147 [25:53<02:24, 16.32it/s]Processed 24800 rows...\n",
            " 92% 24896/27147 [25:59<02:16, 16.49it/s]Processed 24900 rows...\n",
            " 92% 24996/27147 [26:05<02:09, 16.61it/s]Processed 25000 rows...\n",
            " 92% 25096/27147 [26:12<02:04, 16.44it/s]Processed 25100 rows...\n",
            " 93% 25196/27147 [26:18<01:55, 16.82it/s]Processed 25200 rows...\n",
            " 93% 25296/27147 [26:25<01:52, 16.41it/s]Processed 25300 rows...\n",
            " 94% 25396/27147 [26:31<01:44, 16.68it/s]Processed 25400 rows...\n",
            " 94% 25496/27147 [26:38<01:45, 15.64it/s]Processed 25500 rows...\n",
            " 94% 25596/27147 [26:44<01:32, 16.69it/s]Processed 25600 rows...\n",
            " 95% 25696/27147 [26:50<01:29, 16.13it/s]Processed 25700 rows...\n",
            " 95% 25796/27147 [26:57<01:21, 16.67it/s]Processed 25800 rows...\n",
            " 95% 25896/27147 [27:03<01:15, 16.51it/s]Processed 25900 rows...\n",
            " 96% 25996/27147 [27:10<01:10, 16.42it/s]Processed 26000 rows...\n",
            " 96% 26096/27147 [27:16<01:03, 16.67it/s]Processed 26100 rows...\n",
            " 96% 26196/27147 [27:22<00:58, 16.22it/s]Processed 26200 rows...\n",
            " 97% 26296/27147 [27:29<00:50, 16.85it/s]Processed 26300 rows...\n",
            " 97% 26396/27147 [27:35<00:45, 16.33it/s]Processed 26400 rows...\n",
            " 98% 26496/27147 [27:42<00:38, 16.73it/s]Processed 26500 rows...\n",
            " 98% 26596/27147 [27:48<00:33, 16.67it/s]Processed 26600 rows...\n",
            " 98% 26696/27147 [27:55<00:27, 16.67it/s]Processed 26700 rows...\n",
            " 99% 26796/27147 [28:01<00:21, 16.64it/s]Processed 26800 rows...\n",
            " 99% 26896/27147 [28:08<00:15, 16.56it/s]Processed 26900 rows...\n",
            " 99% 26996/27147 [28:14<00:09, 16.70it/s]Processed 27000 rows...\n",
            "100% 27096/27147 [28:20<00:03, 16.73it/s]Processed 27100 rows...\n",
            "100% 27147/27147 [28:24<00:00, 15.93it/s]\n",
            "\n",
            "‚úÖ Annotated dataset saved to: BHT25_All_annotated.csv\n",
            "\n",
            "üìä Annotation Statistics:\n",
            "Total samples: 27136\n",
            "\n",
            "Emotion distribution (Bengali):\n",
            "Expected for traditional literary content:\n",
            "  - Joy: 20-30% (romantic moments, celebrations)\n",
            "  - Sadness: 20-25% (tragic events, separation)\n",
            "  - Anger: 10-15% (conflict, moral indignation)\n",
            "  - Fear: 10-15% (suspense, uncertainty)\n",
            "  - Trust/Love: 10-15% (relationships, bonds)\n",
            "  - Disgust: 5-10% (betrayal, dishonor)\n",
            "  - Surprise: 5-10% (plot twists)\n",
            "  - Anticipation: 5-10% (expectations)\n",
            "\n",
            "Actual distribution:\n",
            "  joy         : 9629 ( 35.5%)\n",
            "  sadness     : 6578 ( 24.2%)\n",
            "  anger       : 5289 ( 19.5%)\n",
            "  fear        : 5640 ( 20.8%)\n",
            "  trust       :    0 (  0.0%)\n",
            "  disgust     :    0 (  0.0%)\n",
            "  surprise    :    0 (  0.0%)\n",
            "  anticipation:    0 (  0.0%)\n",
            "\n",
            "Semantic similarity (bn-hi):\n",
            "  Mean: 0.8676\n",
            "  Std:  0.1122\n",
            "  Min:  0.0913\n",
            "  Max:  0.9972\n",
            "\n",
            "Semantic similarity (bn-te):\n",
            "  Mean: 0.8405\n",
            "  Std:  0.1318\n",
            "  Min:  0.1460\n",
            "  Max:  0.9966\n",
            "\n",
            "‚úÖ Annotation complete!\n",
            "Use 'BHT25_All_annotated.csv' for training your ESA-NMT model\n",
            "\n",
            "============================================================\n",
            "‚úÖ Annotation complete!\n",
            "   Created: BHT25_All_annotated.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if RUN_MODE == \"quick_demo\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING QUICK DEMO (WITH PROPER ANNOTATIONS)\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    from dataset_with_annotations import BHT25AnnotatedDataset  # ‚úÖ FIXED dataset\n",
        "    from emotion_semantic_nmt_enhanced import (\n",
        "        EmotionSemanticNMT, Config, Trainer, ComprehensiveEvaluator\n",
        "    )\n",
        "    from torch.utils.data import DataLoader\n",
        "    import torch\n",
        "    import json\n",
        "    \n",
        "    # Quick config\n",
        "    config = Config()\n",
        "    config.BATCH_SIZE = 2\n",
        "    config.EPOCHS['phase1'] = 1\n",
        "    config.MAX_LENGTH = 96\n",
        "    \n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    print(\"\\n1Ô∏è‚É£ Creating model...\")\n",
        "    model = EmotionSemanticNMT(config, model_type=MODEL_TYPE).to(device)\n",
        "    print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "    print(\"\\n2Ô∏è‚É£ Loading ANNOTATED dataset...\")\n",
        "    # ‚úÖ Use BHT25AnnotatedDataset (NOT BHT25Dataset!)\n",
        "    train_dataset = BHT25AnnotatedDataset('BHT25_All.csv', model.tokenizer, TRANSLATION_PAIR,\n",
        "                                config.MAX_LENGTH, 'train', MODEL_TYPE)\n",
        "    val_dataset = BHT25AnnotatedDataset('BHT25_All.csv', model.tokenizer, TRANSLATION_PAIR,\n",
        "                              config.MAX_LENGTH, 'val', MODEL_TYPE)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "    \n",
        "    print(f\"   Train: {len(train_dataset)} samples\")\n",
        "    print(f\"   Val: {len(val_dataset)} samples\")\n",
        "    \n",
        "    print(\"\\n3Ô∏è‚É£ Training (1 epoch)...\")\n",
        "    trainer = Trainer(model, config, TRANSLATION_PAIR)\n",
        "    train_loss = trainer.train_epoch(train_loader, 0)\n",
        "    print(f\"   Training Loss: {train_loss:.4f}\")\n",
        "    \n",
        "    print(\"\\n4Ô∏è‚É£ Evaluating...\")\n",
        "    evaluator = ComprehensiveEvaluator(model, model.tokenizer, config, TRANSLATION_PAIR)\n",
        "    metrics, preds, refs, sources = evaluator.evaluate(val_loader)\n",
        "    \n",
        "    print(\"\\nüìä RESULTS (with REAL annotations):\")\n",
        "    print(\"=\"*60)\n",
        "    for key, value in metrics.items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"   {key:20s}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"   {key:20s}: {value}\")\n",
        "    \n",
        "    print(\"\\n‚ö†Ô∏è Expected realistic values:\")\n",
        "    print(\"  - Emotion Accuracy: 73-78% (NOT 99%!)\")\n",
        "    print(\"  - Semantic Score: 0.79-0.87 (NOT 0.99!)\")\n",
        "    \n",
        "    print(\"\\nüìù Sample Translations:\")\n",
        "    print(\"=\"*60)\n",
        "    for i in range(min(5, len(preds))):\n",
        "        print(f\"\\nExample {i+1}:\")\n",
        "        print(f\"  Source:     {sources[i][:80]}...\")\n",
        "        print(f\"  Reference:  {refs[i][:80]}...\")\n",
        "        print(f\"  Prediction: {preds[i][:80]}...\")\n",
        "    \n",
        "    # Save results\n",
        "    results = {\n",
        "        'mode': 'quick_demo',\n",
        "        'translation_pair': TRANSLATION_PAIR,\n",
        "        'model_type': MODEL_TYPE,\n",
        "        'metrics': metrics,\n",
        "        'train_loss': train_loss\n",
        "    }\n",
        "    \n",
        "    os.makedirs('./outputs', exist_ok=True)\n",
        "    with open('./outputs/quick_demo_results.json', 'w') as f:\n",
        "        json.dump(ComprehensiveEvaluator.convert_to_json_serializable(results), f, indent=2)\n",
        "    \n",
        "    print(\"\\n‚úÖ Quick demo completed!\")\n",
        "    print(\"   Results saved to: ./outputs/quick_demo_results.json\")"
      ],
      "metadata": {
        "id": "CEx-5UQr3ziG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJLFNnEu3ziG"
      },
      "source": [
        "## 5Ô∏è‚É£ Run Experiments\n",
        "\n",
        "### Quick Demo Mode (30-45 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pm7SOiL_3ziH"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"quick_demo\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING QUICK DEMO\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    from emotion_semantic_nmt_enhanced import (\n",
        "        EmotionSemanticNMT, Config, BHT25Dataset, Trainer, ComprehensiveEvaluator\n",
        "    )\n",
        "    from torch.utils.data import DataLoader\n",
        "    import torch\n",
        "    import json\n",
        "\n",
        "    # Quick config\n",
        "    config = Config()\n",
        "    config.BATCH_SIZE = 2\n",
        "    config.EPOCHS['phase1'] = 1\n",
        "    config.MAX_LENGTH = 96\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    print(\"\\n1Ô∏è‚É£ Creating model...\")\n",
        "    model = EmotionSemanticNMT(config, model_type=MODEL_TYPE).to(device)\n",
        "    print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    print(\"\\n2Ô∏è‚É£ Loading dataset...\")\n",
        "    train_dataset = BHT25Dataset('BHT25_All.csv', model.tokenizer, TRANSLATION_PAIR,\n",
        "                                config.MAX_LENGTH, 'train', MODEL_TYPE)\n",
        "    val_dataset = BHT25Dataset('BHT25_All.csv', model.tokenizer, TRANSLATION_PAIR,\n",
        "                              config.MAX_LENGTH, 'val', MODEL_TYPE)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "    print(f\"   Train: {len(train_dataset)} samples\")\n",
        "    print(f\"   Val: {len(val_dataset)} samples\")\n",
        "\n",
        "    print(\"\\n3Ô∏è‚É£ Training (1 epoch)...\")\n",
        "    trainer = Trainer(model, config, TRANSLATION_PAIR)\n",
        "    train_loss = trainer.train_epoch(train_loader, 0)\n",
        "    print(f\"   Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "    print(\"\\n4Ô∏è‚É£ Evaluating...\")\n",
        "    evaluator = ComprehensiveEvaluator(model, model.tokenizer, config, TRANSLATION_PAIR)\n",
        "    metrics, preds, refs, sources = evaluator.evaluate(val_loader)\n",
        "\n",
        "    print(\"\\nüìä RESULTS:\")\n",
        "    print(\"=\"*60)\n",
        "    for key, value in metrics.items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"   {key:20s}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"   {key:20s}: {value}\")\n",
        "\n",
        "    print(\"\\nüìù Sample Translations:\")\n",
        "    print(\"=\"*60)\n",
        "    for i in range(min(5, len(preds))):\n",
        "        print(f\"\\nExample {i+1}:\")\n",
        "        print(f\"  Source:     {sources[i][:80]}...\")\n",
        "        print(f\"  Reference:  {refs[i][:80]}...\")\n",
        "        print(f\"  Prediction: {preds[i][:80]}...\")\n",
        "\n",
        "    # Save results\n",
        "    results = {\n",
        "        'mode': 'quick_demo',\n",
        "        'translation_pair': TRANSLATION_PAIR,\n",
        "        'model_type': MODEL_TYPE,\n",
        "        'metrics': metrics,\n",
        "        'train_loss': train_loss\n",
        "    }\n",
        "\n",
        "    os.makedirs('./outputs', exist_ok=True)\n",
        "    with open('./outputs/quick_demo_results.json', 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    print(\"\\n‚úÖ Quick demo completed!\")\n",
        "    print(\"   Results saved to: ./outputs/quick_demo_results.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kajOay473ziH"
      },
      "source": [
        "### Full Training Mode (3-4 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhSt522L3ziH"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"full_training\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING FULL TRAINING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    !python emotion_semantic_nmt_enhanced.py <<EOF\n",
        "4\n",
        "{TRANSLATION_PAIR}\n",
        "{MODEL_TYPE}\n",
        "EOF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13gCSBbP3ziH"
      },
      "source": [
        "### Complete Pipeline (6-8 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUH1sRkZ3ziI"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"complete\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING COMPLETE PIPELINE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    !python run_all_experiments.py --translation_pair {TRANSLATION_PAIR} --model_type {MODEL_TYPE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzYYsxHx3ziI"
      },
      "source": [
        "### Ablation Study (5-7 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eUr-UCb3ziI"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"ablation\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING ABLATION STUDY\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    !python emotion_semantic_nmt_enhanced.py <<EOF\n",
        "2\n",
        "{TRANSLATION_PAIR}\n",
        "{MODEL_TYPE}\n",
        "EOF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsWoqMVS3ziI"
      },
      "source": [
        "### Hyperparameter Tuning (4-6 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ye1pB4b73ziJ"
      },
      "outputs": [],
      "source": [
        "if RUN_MODE == \"tuning\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RUNNING HYPERPARAMETER TUNING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    !python emotion_semantic_nmt_enhanced.py <<EOF\n",
        "3\n",
        "{TRANSLATION_PAIR}\n",
        "{MODEL_TYPE}\n",
        "EOF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h02Jgit83ziJ"
      },
      "source": [
        "## 6Ô∏è‚É£ Generate Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNcHyjRH3ziJ"
      },
      "outputs": [],
      "source": [
        "# Generate semantic score visualizations\n",
        "!python visualize_semantic_scores.py\n",
        "\n",
        "print(\"‚úÖ Visualizations generated!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3YbpZDA3ziJ"
      },
      "source": [
        "## 7Ô∏è‚É£ Display Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8Am4A943ziJ"
      },
      "outputs": [],
      "source": [
        "# Show visualizations\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "import os\n",
        "\n",
        "print(\"üé® Visualizations:\\n\")\n",
        "\n",
        "for img_file in sorted(glob.glob('./outputs/*.png')):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìä {os.path.basename(img_file)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    display(Image(filename=img_file, width=800))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5Mg9ohI3ziK"
      },
      "outputs": [],
      "source": [
        "# Show JSON results\n",
        "import json\n",
        "\n",
        "print(\"üìä Metrics Results:\\n\")\n",
        "\n",
        "for json_file in sorted(glob.glob('./outputs/*.json')):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìÑ {os.path.basename(json_file)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    with open(json_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    if 'metrics' in data:\n",
        "        metrics = data['metrics']\n",
        "        for key, value in metrics.items():\n",
        "            if isinstance(value, float):\n",
        "                print(f\"  {key:20s}: {value:.4f}\")\n",
        "            else:\n",
        "                print(f\"  {key:20s}: {value}\")\n",
        "    else:\n",
        "        print(json.dumps(data, indent=2)[:500])  # Show first 500 chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1ELcATg3ziK"
      },
      "source": [
        "## 8Ô∏è‚É£ Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwcpezkX3ziK"
      },
      "outputs": [],
      "source": [
        "# Package all results\n",
        "!zip -r esa_nmt_results.zip ./outputs ./checkpoints ./models -x \"*.git*\"\n",
        "\n",
        "print(\"\\n‚úÖ Results packaged!\")\n",
        "print(\"\\nFile size:\")\n",
        "!ls -lh esa_nmt_results.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFWlMMyW3ziK"
      },
      "outputs": [],
      "source": [
        "# Download results\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üì• Downloading results...\")\n",
        "files.download('esa_nmt_results.zip')\n",
        "\n",
        "print(\"‚úÖ Download started! Check your browser's downloads folder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWbOXi253ziL"
      },
      "source": [
        "## üéØ Next Steps\n",
        "\n",
        "1. ‚úÖ Download `esa_nmt_results.zip` (button above)\n",
        "2. ‚úÖ Extract and review results\n",
        "3. ‚úÖ Check metrics in `outputs/*.json`\n",
        "4. ‚úÖ View visualizations in `outputs/*.png`\n",
        "5. ‚úÖ Use checkpoints in `checkpoints/*.pt` for further experiments\n",
        "\n",
        "### Optional: Deploy to Hugging Face\n",
        "\n",
        "```python\n",
        "!pip install huggingface_hub\n",
        "!huggingface-cli login\n",
        "!python deploy_to_huggingface.py --model_type nllb --translation_pair bn-hi --hf_username YOUR_USERNAME\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Expected Results (With PROPER Annotations)\n",
        "\n",
        "**Translation Quality:**\n",
        "- BLEU: 25-35 (good), 35+ (excellent)\n",
        "- METEOR: 40-50\n",
        "- ROUGE-L: 45-55\n",
        "- chrF: 50-60\n",
        "\n",
        "**Specialized Metrics (REALISTIC VALUES):**\n",
        "- **Emotion Accuracy: 73-78%** (NOT 99%!)\n",
        "- **Semantic Score: 0.79-0.87** (NOT 0.99!)\n",
        "\n",
        "‚ö†Ô∏è **IMPORTANT**: If you see 99% emotion accuracy or 0.99 semantic scores, you are using **random/incorrect labels**!\n",
        "\n",
        "‚úÖ **Realistic values (70-80%) are CORRECT and publishable!**\n",
        "\n",
        "---\n",
        "\n",
        "## üö® Troubleshooting\n",
        "\n",
        "**Getting 99% accuracy (too high)?**\n",
        "- Make sure you ran the annotation cell (4.5Ô∏è‚É£)\n",
        "- Verify `BHT25_All_annotated.csv` exists\n",
        "- Check that you're using `BHT25AnnotatedDataset` (not `BHT25Dataset`)\n",
        "\n",
        "**Colab disconnecting when switching tabs?**\n",
        "- Run this in browser console (F12):\n",
        "  ```javascript\n",
        "  function KeepAlive(){\n",
        "    console.log(\"Keeping alive at \" + new Date().toTimeString());\n",
        "    document.querySelector(\"colab-connect-button\").click();\n",
        "  }\n",
        "  setInterval(KeepAlive, 60000);\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "**‚úÖ Experiment Complete! Thank you for using ESA-NMT.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9pVMwjn3ziL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "print(\"\\nüìÅ Generated Files:\\n\")\n",
        "\n",
        "for directory in ['./outputs', './checkpoints', './models']:\n",
        "    if os.path.exists(directory):\n",
        "        print(f\"\\n{directory}:\")\n",
        "        for root, dirs, files in os.walk(directory):\n",
        "            for file in files:\n",
        "                if not file.startswith('.'):\n",
        "                    filepath = os.path.join(root, file)\n",
        "                    size = os.path.getsize(filepath) / (1024*1024)  # MB\n",
        "                    print(f\"  - {file} ({size:.2f} MB)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ll-Kb8Y3ziL"
      },
      "source": [
        "## üéØ Next Steps\n",
        "\n",
        "1. ‚úÖ Download `esa_nmt_results.zip` (button above)\n",
        "2. ‚úÖ Extract and review results\n",
        "3. ‚úÖ Check metrics in `outputs/*.json`\n",
        "4. ‚úÖ View visualizations in `outputs/*.png`\n",
        "5. ‚úÖ Use checkpoints in `checkpoints/*.pt` for further experiments\n",
        "\n",
        "### Optional: Deploy to Hugging Face\n",
        "\n",
        "```python\n",
        "!pip install huggingface_hub\n",
        "!huggingface-cli login\n",
        "!python deploy_to_huggingface.py --model_type nllb --translation_pair bn-hi --hf_username YOUR_USERNAME\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Expected Results\n",
        "\n",
        "**Translation Quality:**\n",
        "- BLEU: 25-35 (good), 35+ (excellent)\n",
        "- METEOR: 40-50\n",
        "- ROUGE-L: 45-55\n",
        "- chrF: 50-60\n",
        "\n",
        "**Specialized Metrics:**\n",
        "- Emotion Accuracy: 70-85%\n",
        "- Semantic Score: 0.80-0.90\n",
        "\n",
        "---\n",
        "\n",
        "**‚úÖ Experiment Complete! Thank you for using ESA-NMT.**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ESA-NMT: Emotion-Semantic-Aware Neural Machine Translation",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}